[{"id":0,"href":"/docs/read/","title":"Read","section":"Docs","content":"dd #  "},{"id":1,"href":"/docs/read/%E6%88%91%E7%9A%84%E4%B8%96%E7%95%8C/","title":"我的世界","section":"Read","content":"hehehe #  "},{"id":2,"href":"/posts/%E5%A6%82%E4%BD%95%E6%89%93%E5%8C%85rpm/","title":"如何打包RPM","section":"Posts","content":"在centos环境中，运行rpmbuild，会生成/home/$USER/rpmbuild目录\n# 先随便指定一个文件生成目录，之后再编写spec文件 $ rpmbuild test.spec $ tree rpmbuild rpmbuild ├── BUILD ├── BUILDROOT ├── RPMS ├── SOURCES ├── SPECS └── SRPMS "},{"id":3,"href":"/posts/%E5%A6%82%E4%BD%95%E6%89%93%E9%80%A0%E6%88%91%E7%9A%84Surbuntu/","title":"如何打造我的Surbuntu（surfacego2 + ubuntu20.04）","section":"Posts","content":"只安装ubuntu单一系统 #  略\n安装软件 #  零、基础准备 #  1. 开启ssh服务 #  sudo apt install ssh # ssh安装后默认开启sshd服务并加入开机启动，如果没有，查看systemctl status sshd # 非enabled状态的话执行systemctl enable sshd # 如果不要求开机启动的话，就不需要做这一步。 2. 安装VIM #  sudo apt install vim 3. 载入维护的/etc/hosts文件 #  不要问为什么，知道的自然知道，不知道本不需要知道。\n4. 安装git #  sudo apt install git 基础配置一下git：\n全局保存密码\ngit config --global credential.helper store 证书问题\ngit config --global http.sslVerify false 设置邮箱、姓名\ngit config --global user.email \u0026#34;you@example.com\u0026#34; git config --global user.name \u0026#34;Your Name\u0026#34; 不显示中文，却显示八进制数字的问题\ngit config --global core.quotepath false 5. 准备proxy #  hosts文件能解决一半github的访问问题。\n剩下的一半依然需要借助proxy来实现。\n如果你能正常访问github，那么不需要。\n6. 基础环境 #  sudo apt install make gcc 7. 其他准备 #  1）unlock login keyring #    Press Alt+F2, type seahorse and press Enter to start the Gnome Keyring Manager:\n  Alternately, open a terminal with Ctrl+F2+T, type seahorse \u0026amp; and press Enter.\n  The \u0026ldquo;Passwords and Keys\u0026rdquo; window should come up as shown below. Under the Passwords tab, select login, right-click on it, and then click on Change Password:\n  The \u0026ldquo;Change Keyring Password\u0026rdquo; box will come up. Type your old password, and then leave the new/confirm password fields blank. Then press OK, and the information box shown below will pop-up; read it, and then click on Use Unsafe Storage to not have to enter your password at each login:\n  Close the keyring manager. After you log out/reboot, you won\u0026rsquo;t be asked for your password any more.\n  2）中文输入法 #  略\n3）一些alias #  习惯了在mac下用open .来打开Finder，ubuntu下默认Files应用是nautilus。编辑环境变量文件把nautilus变成open。\n# vim ~/.zshrc,添加 alias open=\u0026#39;nautilus\u0026#39; sublime_text\nalias sublime=\u0026#39;/opt/sublime_text/sublime_text\u0026#39; 一、打造Shell #  1. oh-my-zsh #  安装oh-my-zsh #  sudo apt update sudo apt install curl sudo apt install zsh sh -c \u0026#34;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 安装必要插件 #  在$HOME/.oh-my-zsh/custom/plugins目录下clone\ngit clone git://github.com/zsh-users/zsh-autosuggestions git clone https://github.com/zsh-users/zsh-syntax-highlighting.gi 修改~/.zshrc文件\nplugins=(git zsh-autosuggestions zsh-syntax-highlighting) 更改主题：powerlevel10k #  下载主题\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k # 国内可以使用gitee上的官方镜像 git clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k 修改～/.zshrc文件\nZSH_THEME=\u0026#34;powerlevel10k/powerlevel10k\u0026#34; 安装缺少的字体\n为了减少折腾并且减少空间，统一使用MesloLGS NF系列的Nerd Font，也是powerlevel10k库提供的字体文件：\nMesloLGS NF Regular.ttf\nMesloLGS NF Bold.ttf\nMesloLGS NF Italic.ttf\nMesloLGS NF Bold Italic.ttf\n下载到本地双击安装即可\n2. 安装shell主题 #  当然是安装我最喜欢的Gruvbox Dark主题，给gnome-shell\n通过Gogh安装\nbash -c \u0026#34;$(wget -qO- https://git.io/vQgMr)\u0026#34; 选择gruvbox dark主题\n2. neovim #  sudo apt install neovim 3. spacevim #  curl -sLf https://spacevim.org/cn/install.sh | bash 安装完成之后，vim/nvim命令打开vim会自动安装插件\n如果报错[vimproc] vimproc\u0026rsquo;s DLL:问题,\n执行:VimProcInstall修复\n4. emacs #  由于ubuntu20.04源带的emacs版本太低，于是选择编译安装emacs最新版\n下载源码包\nwget http://mirror.team-cymru.com/gnu/emacs/emacs-27.2.tar.gz tar zxvf emacs-27.2.tar.gz cd emacs-27.2 准备编译环境\nsudo apt install autoconf make gcc texinfo libgtk-3-dev libxpm-dev libjpeg-dev libgif-dev libtiff5-dev libncurses5-dev libxml2-dev libgnutls28-dev 运行./autogen.sh\n./autogen.sh ./configure make -j 2 sudo make install 5. spacemacs #  安装sqlite3\nsudo apt install sqlite3 安装spacemacs\ngit clone https://github.com/syl20bnr/spacemacs ~/.emacs.d 6. org-roam #  用emacs主要用来构建知识体系的免费解决方案，obsidian的替代品。\n涉及到org-mode，org-roam，org-roam-server，org-protocol等的配置。\n具体配置内容会单开一篇文章来整理。\n7. Tmux #  tmux\n8. fusuma #  触控板手势配置程序。\nIMPORTANT: You MUST be a member of the INPUT group to read touchpad by Fusuma.\n$ sudo gpasswd -a $USER input Then, You apply the change with no logout or reboot.\n$ newgrp input   Install libinput-tools\nYou need libinput release 1.0 or later.\n  $ sudo apt-get install libinput-tools  Install Ruby\nFusuma runs in Ruby, so you must install it first.\n  $ sudo apt-get install ruby Install Fusuma  $ sudo gem install fusuma  Install xdotool (optional)\nFor sending shortcuts:\n  $ sudo apt-get install xdotool 7. 配置文件更新 #  恢复备份在git仓库的spacemacs等配置文件。\n二、安装必备软件 #  1. 安装Edge #  下载地址：microsoft-edge-linux\nsudo apt install libatomic1 sudo dpkg -i microsoft-edge-beta_91.0.864.37_1_amd64.deb 之后同步微软账号，就可以接入其他设备的配置、历史记录、集锦（阅读列表）了。\n2. 安装Vscode #  sudo dpkg -i code_1.56.2-1620838498_amd64.deb 开启配置文件同步\n3. Xournal++ #  sudo add-apt-repository ppa:andreasbutti/xournalpp-master sudo apt update sudo apt install xournalpp 4. Typora #  # or use # sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE wget -qO - https://typora.io/linux/public-key.asc | sudo apt-key add - # add Typora\u0026#39;s repository sudo add-apt-repository \u0026#39;deb https://typora.io/linux ./\u0026#39; sudo apt-get update # install typora sudo apt-get install typora 5. Obsidian #  通过flatpak安装，首先安装flatpak\nsudo apt install flatpak 下载flatpak文件，安装\nflatpak install md.obsidian.Obsidian.flatpakref 6. VirtualBox #  sudo apt install virtualbox 7. Parsec #  官网下载deb包安装。\n8. Krita #  通过官网下载flatpak安装。\n9. sublime-text4 #  正好发布了4的版本，通过apt安装\nwget -qO - https://download.sublimetext.com/sublimehq-pub.gpg | sudo apt-key add - sudo apt-get install apt-transport-https echo \u0026#34;deb https://download.sublimetext.com/ apt/stable/\u0026#34; | sudo tee /etc/apt/sources.list.d/sublime-text.list sudo apt-get update sudo apt-get install sublime-text 10. Pgyvpn #  安装蒲公英客户端，官网下载deb包安装。\n11. Chiaki #  PS remote play in linux.\n12. Dolphin #  必备的任天堂wii模拟器。\n13. ppsspp #  psp模拟器\n14. pscx2 #  基础环境及依赖包的安装\nsudo dpkg --add-architecture i386 sudo apt install cmake gcc-multilib g++-multilib sudo apt install libaio-dev:i386 libbz2-dev:i386 libcggl:i386 libegl1-mesa-dev:i386 libglew-dev:i386 libgles2-mesa-dev:i386 libgtk2.0-dev:i386 libjpeg-dev:i386 libsdl1.2-dev:i386 libwxgtk3.0-gtk3-dev:i386 nvidia-cg-toolkit zlib1g-dev:i386 libsdl2-dev:i386 libjack-jackd2-dev:i386 libportaudiocpp0:i386 portaudio19-dev:i386 liblzma-dev:i386 libsoundtouch-dev:i386 libxml2-dev:i386 libpcap0.8-dev:i386 添加源\n# sudo vim /etc/apt/source.list deb http://us.archive.ubuntu.com/ubuntu/ trusty multiverse deb-src http://us.archive.ubuntu.com/ubuntu/ trusty multiverse deb http://us.archive.ubuntu.com/ubuntu/ trusty-updates multiverse deb-src http://us.archive.ubuntu.com/ubuntu/ trusty-updates multiverse add-apt-repository\nsudo add-apt-repository ppa:gregory-hainaut/pcsx2.official.ppa sudo apt-get update 安装包\nsudo apt-get install pcsx2 15. VLC #  sudo apt install vlc 16. Synaptic #  sudo apt install synaptic 17. Tmux #  sudo apt install tmux 18. 安装deepin系软件(源的安装包都不见了) #  wget -O- https://deepin-wine.i-m.dev/setup.sh | sh 三、准备coding环境 #  1. golang环境 #  官网下载go的压缩包\nrm -rf /usr/local/go \u0026amp;\u0026amp; tar -C /usr/local -xzf go1.14.3.linux-amd64.tar.gz 加入环境变量\nexport PATH=$PATH:/usr/local/go/bin 配置代理\ngo env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.cn,direct 2. Nodejs环境 #  安装稳定版nodejs\ntar -C ~/. -xf node-v14.17.0-linux-x64.tar.xz 3. Miniconda 环境 #  下载安装官方miniconda python3.9最新版，一路yesyes\n记得取消默认base环境\nconda config --set auto_activate_base false 4. Flutter 环境 #  略\n"},{"id":4,"href":"/posts/vscode%E4%B8%ADanaconda%E7%9A%84python-debug/","title":"vscode中anaconda的python debug","section":"Posts","content":"在调试ioserver的过程中，发现并没有正常条转到断点。\n原因是在conda的环境ioserver中，安装了项目打包后的程序，导致从.vscode目录下的settings.json中配置的环境变量PYTHONPATH的效果抵消了。\n于是卸载了项目打包后的程序，之后，重新正确配置PYTHONPATH\n{ \u0026#34;python.pythonPath\u0026#34;: \u0026#34;/Users/cosmo/miniconda3/envs/the_env/bin/python\u0026#34;, \u0026#34;terminal.integrated.env.osx\u0026#34;: {\u0026#34;PYTHONPATH\u0026#34;:\u0026#34;${workspaceFolder}\u0026#34;} } 解决问题。\n"},{"id":5,"href":"/posts/%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89npm%E4%BB%93%E5%BA%93/","title":"搭建私有npm仓库","section":"Posts","content":"发布到npm仓库（本地使用verdaccio搭建私有npm仓库） #  # 全局安装verdaccio npm install -g verdaccio # 启动verdaccio verdaccio # 创建verdaccio用户 npm adduser --registry http://localhost:4873 # 发布包 npm publish --registry http://localhost:4873 # "},{"id":6,"href":"/posts/node_exporter%E7%BD%91%E7%BB%9C%E6%8C%87%E6%A0%87/","title":"Prometheus node_exporter网络指标","section":"Posts","content":"node_exporter中的网络相关指标由node_network前缀开头。\n我们可以通过访问node_exporter的服务端口，直接查看该节点的各项指标：\n其中，常用指标有\n node_network_receive_bytes_total：网卡上传累计字节数 node_network_transmit_bytes_total：网卡下载累计字节数  其中选项device代表每个网卡。\n通过Prometheus计算上传速率/下载速率的查询语句：\n  上传速率：irate(node_network_transmit_bytes_total{device!=\u0026ldquo;lo\u0026rdquo;}[1m]) by (instance, job)\n  下载速率：irate(node_network_receive_bytes_total{device!=\u0026ldquo;lo\u0026rdquo;}[1m]) by (instance, job)\n  device : 代表网卡\nirate : 分组函数，取的是在指定时间范围内的最近两个数据点来算速率\n[1m] : 分组的时长\nby(instance,job) : 代表按job、instance分组\n"},{"id":7,"href":"/posts/%E6%88%91%E7%9A%84Terminal%E4%B8%8D%E5%8F%AF%E8%83%BD%E8%BF%99%E4%B9%88%E5%A5%BD%E7%94%A8/","title":"我的Terminal不可能这么好用","section":"Posts","content":"终端美化 #  Use powerlevel10k to config terminal\n配色\n字体\n常用快捷键 #           删除命令行光标前的字符 ctrl + u   快速跳转到命令行首 ctrl + a   快速跳转到命令行尾 ctrl + e    NeoVIM打造IDE #  关于NeoVim：blablabla\nStep 1 安装neovim #  Windows #  with Chocolatey\nchoco install neovim with Scoop\nscoop bucket add versions scoop install neovim-nightly macOS / OS X #  通过Homebrew 安装\nbrew install neovim Ubuntu / Debian #  sudo apt install neovim Arch #  sudo pacman -Sy neovim Step 2 插件管理器 #  Step 3 如虎添翼的插件 #  Vim常用快捷键 #           翻页 ctrl + f, ctrl + b   跳到第一行 gg   跳到最后一行 G   行内移动\u0026ndash;移动到行尾 $   行内移动\u0026ndash;移动到行首不包括空格 ^   行内移动-移动到行首包括空格 0   行内移动-向右按字 w   行内移动-向左按字 b       "},{"id":8,"href":"/posts/emqx%E4%BD%93%E7%B3%BB%E5%88%86%E6%9E%90/","title":"emqx体系分析","section":"Posts","content":"EMQ X是什么。。。\nEMQX Broker #  完全开源，提供一个管理平台和mqtt broker。\n安装release版本rpm包，启动servie\n#docker pull emqx/emqx:4.2.7  #docker run -d --name emqx -p 1883:1883 -p 8083:8083 -p 8883:8883 -p 8084:8084 -p 18083:18083 emqx/emqx:4.2.7 sudo systemctl start emqx 启动EMQX客户端连接测试成功。\n1. 首先，还是来看看Kuiper #  kuiper是用golang编写的开源的流式处理软件，支持标准的流式SQL，支持从 MQTT 服务器、EdgeX 消息总线和 HTTP 服务等数据源消费数据，将分析结果通过 MQTT 消息发送、HTTP 服务调用和时序数据库储等。\n简单使用Kuiper #  1.下载Kuiper的release版本并安装 #  #docker pull emqx/kuiper:1.1.1 #docker run -p 9081:9081 -d --name kuiper -e MQTT_SOURCE__DEFAULT__SERVERS=[tcp://127.0.0.1:1883] emqx/kuiper:1.1.1 sudo systemctl start kuiper # 后台以进程kuiperd运行 查看配置文件，配置kuiper默认端口、mqtt source端口\n# kuiper.yaml文件，修改kuiper默认端口 vim /etc/kuiper/kuiper.yaml # mqtt_source.json文件，修改mqtt源端口 vim /etc/kuiper/mqtt_source.json 2.创建流（stream）流式数据的结构定义，类似于数据库中的表格类型定义。 #  流对应mqtt源的一类消息订阅规则，并映射接受的消息格式。\nkuiper create stream demo \u0026#39;(temperature float, humidity bigint) WITH (FORMAT=\u0026#34;JSON\u0026#34;, DATASOURCE=\u0026#34;devices/+/messages\u0026#34;)\u0026#39; 3.从消息的发送端到kuiper引擎 #  进入命令行，设置一条规则\n# 进入命令行 kuiper query # 设置一条规则 kuiper \u0026gt; select * from demo WHERE temperature \u0026gt; 30; # 之后一旦有符合规则的数据接入，数据就会过滤 # 1. 以命令行方式进入kuiper，一次只能生效一条规则。 # 2. 消息的发送端只能以json对象，而不是json数组的形式产生数据 4.数据往哪里去？ #  参考EdgeX的接入说明：\n在 EdgeX Geneva 版本中, EMQ X Kuiper - 基于 SQL 的轻量级流式数据处理软件与 EdgeX 进行了集成。在进入这篇教程之前，让我们先花一些时间来了解一些 Kuiper 的基本知识。EMQ X Kuiper 是 Golang 实现的轻量级物联网边缘分析、流式处理开源软件，可以运行在各类资源受限的边缘设备上。Kuiper 基于源 (Source)，SQL (业务逻辑处理)， 目标 (Sink) 的方式来支持流式数据处理。\n 源（Source）：流式数据的数据源，例如来自于 MQTT 服务器的数据。在 EdgeX 的场景下，数据源就是 EdgeX 消息总线（EdgeX message bus），可以是来自于 ZeroMQ 或者 MQTT 服务器； SQL：SQL 是你流式数据处理指定业务逻辑的地方，Kuiper 提供了 SQL 语句可以对数据进行抽取、过滤和转换； 目标（Sink）：目标用于将分析结果发送到特定的目标。例如，将分析结果发送到另外的 MQTT 服务器，或者一个 HTTP Rest 地址；  使用 Kuiper，一般需要完成以下三个步骤。\n 创建流，就是你定义数据源的地方 写规则  为数据分析写 SQL 指定一个保存分析结果的目标   部署，并且运行规则  5. 自定义Sink #  命令行写query规则无法配置Sink，默认规则指定的Sink是LogSink，输出到页面上。\n测试自定义Sink通过Rest接口调用。\nAPI #   获取版本号  GET http://localhost:9081 # response { \u0026#34;version\u0026#34;: \u0026#34;1.0.1-22-g119ee91\u0026#34;, \u0026#34;os\u0026#34;: \u0026#34;darwin\u0026#34;, \u0026#34;upTimeSeconds\u0026#34;: 14 }  ping  GET http://localhost:9081/ping   流\n  创建流\nPOST http://localhost:9081/streams # request {\u0026#34;sql\u0026#34;:\u0026#34;create stream my_stream (id bigint, name string, score float) WITH ( datasource = \\\u0026#34;topic/temperature\\\u0026#34;, FORMAT = \\\u0026#34;json\\\u0026#34;, KEY = \\\u0026#34;id\\\u0026#34;)\u0026#34;}   显示流\nGET http://localhost:9081/streams # response [\u0026#34;demo\u0026#34;]   描述流\nGET http://localhost:9081/streams/{id}}   更新流\nPUT http://localhost:9081/streams/{id} #request id是原有流定义的id或名称 {\u0026#34;sql\u0026#34;:\u0026#34;create stream my_stream (id bigint, name string, score float) WITH ( datasource = \\\u0026#34;topic/temperature\\\u0026#34;, FORMAT = \\\u0026#34;json\\\u0026#34;, KEY = \\\u0026#34;id\\\u0026#34;)\u0026#34;}   删除流\nDELETE http://localhost:9081/streams/{id}     规则\n  创建规则\nPOST http://localhost:9081/rules # request { \u0026#34;id\u0026#34;: \u0026#34;rule1\u0026#34;, \u0026#34;sql\u0026#34;: \u0026#34;select temperature as temp2, humidity as hum2 from demo where temperature \u0026gt; 30\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;log\u0026#34;: {} }, { \u0026#34;mqtt\u0026#34;: { \u0026#34;server\u0026#34;: \u0026#34;tcp://10.168.1.168:1883\u0026#34;, \u0026#34;topic\u0026#34;: \u0026#34;kuiper/test/messages\u0026#34; } } ] } # response Rule rule1 was created successfully.   展示规则\nGET http://localhost:9081/rules # 获取不到命令行query的规则   描述规则\nGET http://localhost:9081/rules/{id}   更新规则\nPUT http://localhost:8080/rules/{id}   删除规则\nDELETE http://localhost:8080/rules/{id}   启动规则\nPOST http://localhost:8080/rules/{id}/start   停止规则\nPOST http://localhost:8080/rules/{id}/stop   重启规则\nPOST http://localhost:8080/rules/{id}/restart   获取规则的状态\nGET http://localhost:8080/rules/{id}/status     插件\n  Kuiper规则引擎的实现逻辑 #  Kuiper有两个入口：cli命令行与server\n cli: xstream/cli/main.go: 通过命令行的方式创建stream、rule、plugin；通过query命令启动命令提示符可以做查询测试。 server: xstream/server.go: 通过kuiperd后台启动，启动过程中会启动ruleProssesor、prometheus、rest、rpc、  扩展 #  增加扩展插件的关键步骤：\n  设置golang插件开发环境。\n  实现api接口函数。\n  处理配置：可在kuiper.yaml文件中增加自定义配置，并在插件的处理逻辑中获取该配置。\n  扩展分类\n  源扩展：实现自定义数据流来源\n  Sink扩展：实现自定义数据目标\n  函数扩展：实现自定义sql函数\n  2. EMQX、EMQX Broker、EMQX Enterprise、EMQX Edge的区别 #  哪些开源，哪些不开源，功能上的差异。\n3. EMQX 与Kuiper规则引擎的区别 #  emqx中规则引擎的实现\n"},{"id":9,"href":"/posts/Tmux%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E5%BE%97%E6%9B%B4%E9%A1%BA%E6%89%8B/","title":"Tmux如何使用得更顺手","section":"Posts","content":"安装Tmux #  mac下安装：\nbrew install tmux Tmux 美化 #  oh my tmux，使用powerline\ngit clone https://github.com/gpakosz/.tmux.git 设置tmux配置文件\nTmux顺手快捷键 #  常用快捷键列表\n         创建窗格（左右分隔） Ctrl + b %   创建窗格（上下分隔） Ctrl + b \u0026quot;   光标切换窗格 Ctrl + b    切换到上一个窗格 Ctrl + b ;   切换到下一个窗格 Ctrl + b o   调整窗格大小 Ctrl + b Alt                                                        "},{"id":10,"href":"/posts/Ubuntu-20.04%E5%AE%89%E8%A3%85microstack%E5%87%BA%E9%94%99/","title":"Ubuntu 20.04安装microstack出错","section":"Posts","content":"Ubuntu 20.04安装microstack出错 #  安装\n$ sudo snap install microstack --devmode --beta 失败\n查看日志\n$ systemctl status snap.microstack.load-modules.service modprobe: ERROR: could not insert \u0026#39;vhost_vsock\u0026#39;: Device or resource busy 由于linux检测到在vmware环境中运行时，会加载vmware的模块并使用vsock产生了冲突。\n通过命令查看冲突：\n$ lsmod | grep vsock vmw_vsock_virtio_transport_common 32768 0 vmw_vsock_vmci_transport 32768 1 vsock 36864 3 vmw_vsock_virtio_transport_common,vmw_vsock_vmci_transport vmw_vmci 69632 2 vmw_balloon,vmw_vsock_vmci_transport 解决办法：\n创建编辑配置文件：/etc/modprobe.d/blacklist-vmware.conf\n$ sudo vi /etc/modprobe.d/blacklist-vmware.conf ## 加入以下两行 blacklist vmw_vsock_virtio_transport_common blacklist vmw_vsock_vmci_transport 重新执行安装：\n$ sudo snap install microstack --devmode --beta microstack (beta) ussuri from Canonical?? installed "},{"id":11,"href":"/posts/Ubuntu-20.04-%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2microstack/","title":"Ubuntu 20.04 单节点安装部署microstack","section":"Posts","content":"Ubuntu 20.04 单节点安装部署microstack #  1. 安装 #  通过snap安装，如果没有snap请先安装snap。\n执行以下命令安装：\n$ sudo snap install microstack --devmode --beta 如果安装成功，则跳到第二部分初始化。\n如果安装完提示未成功，systemctl查看status提示\nmodprobe: ERROR: could not insert \u0026lsquo;vhost_vsock\u0026rsquo;: Device or resource busy\n则查看是否有冲突\n$ lsmod | grep vsock # vsock模块冲突 vmw_vsock_virtio_transport_common 32768 0 vmw_vsock_vmci_transport 32768 1 vsock 36864 3 vmw_vsock_virtio_transport_common,vmw_vsock_vmci_transport vmw_vmci 69632 2 vmw_balloon,vmw_vsock_vmci_transport 解决办法：\n创建编辑配置文件 /etc/modprobe.d/blacklist-vmware.conf\n$ sudo vi /etc/modprobe.d/blacklist-vmware.conf ## 加入以下两行 blacklist vmw_vsock_virtio_transport_common blacklist vmw_vsock_vmci_transport 重启后重新执行安装。\n2. 初始化 #  执行命令：\n$ sudo microstack init --auto --control 上述步骤回配置并启动了服务。\n"},{"id":12,"href":"/posts/grafana%E5%85%8D%E7%99%BB%E5%BD%95/","title":"grafana免登录","section":"Posts","content":"在ubuntu下，grafana以systemctl管理的service的方式运行，修改默认环境变量配置文件：\n/etc/default/grafana-server文件\n增加以下环境变量配置：\nGF_AUTH_PROXY_ENABLED=true GF_AUTH_ANONYMOUS_ENABLED=true "},{"id":13,"href":"/posts/golang%E6%A8%A1%E5%9D%97%E5%BC%80%E5%8F%91/","title":"golang模块开发","section":"Posts","content":"[[golang]]\ngolang模块开发流程：\n  创建项目目录\n$ mkdir myapp $ cd myapp   模块初始化， 会生成go.mod文件\n$ go mod init myapp   创建main入口文件\n// 文件名随意，但package要是main package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Welcome\u0026#34;) }   引入第三方库之后，执行go mod vendor下载\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;gopkg.in/alecthomas/kingpin.v2\u0026#34; ) func main() { kingpin.Parse() fmt.Println(\u0026#34;Welcome\u0026#34;) } 在代码中引入包后执行，会主动下载包\n$ go mod vendor go: finding module for package gopkg.in/alecthomas/kingpin.v2 go: found gopkg.in/alecthomas/kingpin.v2 in gopkg.in/alecthomas/kingpin.v2 v2.2.6 go: finding module for package github.com/alecthomas/units go: finding module for package github.com/alecthomas/template go: downloading github.com/alecthomas/units v0.0.0-20210208195552-ff826a37aa15 go: found github.com/alecthomas/template in github.com/alecthomas/template v0.0.0-20190718012654-fb15b899a751 go: found github.com/alecthomas/units in github.com/alecthomas/units v0.0.0-20210208195552-ff826a37aa15  "},{"id":14,"href":"/posts/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2prometheus/","title":"安装部署prometheus","section":"Posts","content":"安装步骤 #  一、安装prometheus #  部署路径：/usr/local/prometheus\n服务文件：/usr/lib/systemd/system/prometheus.service\n部署过程:\n1. 解压文件，复制到指定路径 #  tar zxvf prometheus-2.22.2.linux-amd64.tar.gz mv prometheus-2.22.2.linux-amd64 prometheus cp -r prometheus /usr/local/ 2. 创建service服务文件 #  vim /usr/lib/systemd/system/prometheus.service [Unit] Description=Prometheus After=network.target [Service] ExecStart=/usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml --storage.tsdb.path=/data/prometheus --storage.tsdb.retention.time=180d --storage.tsdb.retention.size=29TB User=root [Install] WantedBy=multi-user.target 其中，执行命令涉及的参数如下：\n config.file：配置文件路径。 storage.tsdb.path：tsdb存储路径，默认是相对于执行路径的/data目录。 storage.tsdb.retention.time：数据保存的最长时间，这里是180天。 storage.tsdb.retention.size：数据保存的最大量值，这里最大保存29TB的数据，再有更多的数据，则会删除最早的历史数据来腾出空间。  加入开机启动：\nsystemctl enable prometheus systemctl start prometheus 3. 修改prometheus配置文件 #  这里根据实际情况有针对性的修改（需要先在节点上部署node_exporter和process-exporter）\n# 配置文件简单描述 # my global config global: scrape_interval: 1s # 抓取数据的频率，这里设置为1秒 evaluation_interval: 1s # 计算规则的频率（用不到），这里设置为1秒 # ...省略中间默认配置 # A scrape configuration containing exactly one endpoint to scrape: # Here it\u0026#39;s Prometheus itself. # 这里开始配置要抓取数据的对象,一个抓取配置对应一个job，可以把同类或同组节点放到一个job里抓取 scrape_configs: # 指定一个job名称，job名称可以在查询时作为参数 - job_name: \u0026#39;prometheus\u0026#39; # target配置，以http协议传输数据,9090是prometheus的端口，node_exporter的端口是9100，process-exporter的端口是9256 static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] - job_name: \u0026#39;test_job\u0026#39; static_configs: - targets: [\u0026#39;test01:9100\u0026#39;, \u0026#39;test01:9256\u0026#39;] - targets: [\u0026#39;test02:9100\u0026#39;, \u0026#39;test02:9256\u0026#39;] # ... 二、 安装node_exporter 和process-exporter #  1. 安装node_exporter #  解压、拷贝\ntar zxvf node_exporter-1.0.1.linux-amd64.tar.gz mv node_exporter-1.0.1.linux-amd64 node_exporter cp -r node_exporter /usr/local/ 创建service并开机启动\n# vim node_exporter.service vim /usr/lib/systemd/system/node_exporter.service # node_exporter.service的内容 [Unit] Description=Node Exporter After=network.target [Service] ExecStart=/usr/local/node_exporter/node_exporter User=root [Install] WantedBy=multi-user.target # 设置开机启动并启动 systemctl enable node_exporter systemctl start node_exporter 2. 安装process-exporter #  解压、拷贝\ntar zxvf process-exporter-0.7.5.linux-amd64.tar.gz mv process-exporter-0.7.5.linux-amd64 process-exporter cp -r process-exporter /usr/local/ 创建process-exporter配置文件\n# vim /usr/local/process-exporter/all.yaml vim /usr/local/process-exporter/all.yaml # 编辑内容： process_names: - name: \u0026#34;{{.Comm}}\u0026#34; cmdline: - \u0026#39;.+\u0026#39; 创建service并开机启动\nvim /usr/lib/systemd/system/process_exporter.service # 编辑的内容 [Unit] Description=Process Exporter for Prometheus [Service] User=root ExecStart=/usr/local/process-exporter/process-exporter --config.path /usr/local/process-exporter/all.yaml --web.listen-address=:9256 KillMode=process Restart=always [Install] WantedBy=multi-user.target # 设置开机启动 systemctl enable process_exporter systemctl start process_exporter "},{"id":15,"href":"/posts/Elastic-Search%E7%9A%84%E5%85%A8%E6%96%87%E6%90%9C%E7%B4%A2/","title":"Elastic Search的全文搜索","section":"Posts","content":"搜索方式 #  查询DSL #  Elasticsearch提供基于JSON的完整查询DSL来定义查询。查询DSL包括两种子句：\n 叶查询子句：在特定的字段上查找特定的值，如match、term或range查询。 复合查询子句：包含其他叶查询或复合查询子句，以合理的方式结合多条查询（比如bool或dis_max查询），或者改变查询行为（比如not或constant_score查询）。  根据匹配和计算方式不同，查询类别分为两类。\n 查询(query)用于检查内容与条件是否匹配，并且计算_score元字段表示匹配度。查询的结构中以query参数开始来执行内容查询。 过滤(filter)不计算匹配得分，只是简单的决定文档是否匹配。内容过滤主要通过过滤结构化数据，例如时间、数值、not_analyze的文本等。  查询(query)的子句也可以传递filter参数，比如bool查询内的filter、constant_score查询内的filter参数。\n( \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Search\u0026#34;}\t}, { \u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;Elasticsearch\u0026#34;} } ], \u0026#34;filter\u0026#34;: [ {\u0026#34;term\u0026#34;: {\u0026#34;status\u0026#34;: \u0026#34;published\u0026#34;}}, {\u0026#34;range\u0026#34;: {\u0026#34;publish_date\u0026#34;: {\u0026#34;gte\u0026#34;: \u0026#34;2019-01-01\u0026#34;}}} ] } } ) 全文搜索 #  标准查询接受文本/数字/日期的查询，分析参数并组成查询条件。例如：\n{ \u0026#34;match\u0026#34;: { \u0026#34;message\u0026#34;: \u0026#34;this is a test\u0026#34;} } message是字段名，可以用任何字段的名（包括_all）来替换。\n有三种类型的match查询：布尔（boolean）、短语（phrase）和短语前缀（phrase_prefix）。除此之外还有多段查询、Lucene语法查询、简化查询。\n1. 布尔查询 #  默认的标准查询类型，分析文本并组成一个布尔查询。operator参数可以设置为or或and来控制布尔子句（默认为or）。用于匹配的should子句的最小数量可以使用minimun_should_match参数来设置。\n可以设置analyzer来控制在文本上执行分析过程的分词器。默认是使用字段映射中明确定义或者默认的搜索分词器。\nlenient参数可以设置为true来忽略数据类型匹配出错造成的一场，例如尝试通过文本查询字符串来查询数字类型字段。默认为false。\n（1）模糊匹配\nfuzziness可以对请求的字段类型进行模糊匹配。prefix_length和max_expansions在这种情况下可以用来控制模糊过程。\n"},{"id":16,"href":"/posts/ElasticSearch%E4%BA%8C/","title":"ElasticSearch(二)","section":"Posts","content":"Elastic Search中的数据建模方法 #  要想让查询速度更快，让更新更容易而且代价更小，定义数据结构是要解决的关键问题之一。虽然大多数NoSQL方案都无法提供关系型映射和查询，蛋ES仍然提供了一些管理关系型数据的方法。\n在Elasticsearch中主要有4中定义文档结构的方法：\n 扁平式结构（应用侧关联） 数据反范式化 嵌套对象 父子关系  扁平式结构：在扁平式结构中，最简单的键值对索引文档，有时候也用简单对象（plain objects）的形式。数据存储成这种格式可以索引更快，也可以查询更快。缺点是会导致难以维护不同实体之间的关系。使用扁平式结构之后，就经常要在应用代码中做关联，以发现文档之间的关系。\n数据反范式化：把其他文档内的相关字段多复制一份，目的只是为了维护实体之间的关系。这种方法可用于维护扁平式结构，也可以通过在每份文档中多保存一到多个字段来维护它们之间的关系。这种方法速度很快，但会多占用大量空间，因为有时候要处理很多份副本。\n嵌套与父子关系：这些关系是Elasticsearch为管理关系型数据而自带的解决方案。\n"},{"id":17,"href":"/posts/oracle%E4%B8%AD%E7%9A%84merge-into/","title":"oracle中的merge into","section":"Posts","content":"oracle merge into #  MERGE INTO A_MERGE A USING (select B.AID,B.NAME,B.YEAR from B_MERGE B) C ON (A.id=C.AID) WHEN MATCHED THEN UPDATE SET A.YEAR=C.YEAR WHEN NOT MATCHED THEN INSERT(A.ID,A.NAME,A.YEAR) VALUES(C.AID,C.NAME,C.YEAR); commit; "},{"id":18,"href":"/posts/ElasticSearch%E4%B8%80/","title":"ElasticSearch(一)","section":"Posts","content":"什么叫全文检索？ #  对非结构化的数据/结构化数据建立索引，再对索引进行搜索文档的过程就叫全文检索(Full-text Search)。\n数据格式（分类） #   非结构化数据：没有固定格式的数据（html网页，文章，txt， excel） \u0026mdash; 没有定长，字段，描述 结构化数据：有固定格式数据（数据库一行数据） \u0026mdash; 有固定长度（varchar(50)），字段，描述  倒排索引 #  搜索采用倒排索引算法\n  顺序扫描法：有一本词典，这本词典没有目录，查询一个词语只能从第一页开始，一页一页查询，直到找到为止。（数据库采用顺序扫描法 \u0026mdash;\u0026gt; 但可以建立索引，也是倒排索引）\n  倒排扫描法：有一本词典，有目录，查询一个词语，只需查询目录，从目录找到词语所在页码。\n  问题：为什么不使用数据库进行海量数据索引（虽然数据库也可以建立倒排索引进行搜索）？\n数据库缺点：\n  全表扫描 \u0026mdash;速度非常慢\n  字段中所有的内容都要挨个匹配 \u0026mdash;速度慢\n  全文检索问题\n%口罩罩% 无法实现分词搜索\n  建立索引，全文检索不走索引\nlike不走索引，不建分词\n  什么叫做文档？ #  所谓的文档就是一条结构化数据 \u0026mdash;-\u0026gt;表现形式 对象\u0026mdash;\u0026gt;方便java api操作数据\n全文检索场景 #   搜索引擎 站内搜索 系统文件搜索  ES与Solr的区别 #  建立索引的过程e #  如何根据索引词典去搜索文档对象 # "},{"id":19,"href":"/posts/Centos7-kubernetes%E6%90%AD%E5%BB%BA/","title":"Centos7 kubernetes搭建","section":"Posts","content":"环境准备 #  机器环境 #  节点CPU核数\u0026gt;=2\nDNS网络\nlinux内核\u0026gt;4以上，Centos 7 内核默认是3.10.0\n准备3台虚拟机环境\n依赖环境 #  # 给机器设置主机名 hostnamectl set-hostname master01 hostnamectl set-hostname node01 hostnamectl set-hostname node02 # 查看主机名 hostname # 配置IP host映射关系 vi /etc/hosts 192.168.255.10 master01 192.168.255.11 node01 192.168.255.12 node02 # 安装依赖环境 yum install -y conntrack ntpdate ntp ipvsadm ipset jq iptables curl sysstat libseccomp wget vim net-tools git iproute lrzsz bash-completion tree bridge- utils unzip bind-utils gcc # 安装iptables，启动iptables，设置开机启动，清空iptables规则，保存当前规则到默认规则 # 关闭防火墙 systemctl stop firewalld \u0026amp;\u0026amp; systemctl disable firewalld # 置空iptables yum -y install iptables-services \u0026amp;\u0026amp; systemctl start iptables \u0026amp;\u0026amp; systemctl enable iptables \u0026amp;\u0026amp; iptables -F \u0026amp;\u0026amp; service iptables save # 关闭selinux # 关闭swap分区并且永久关闭虚拟内存 swapoff -a \u0026amp;\u0026amp; sed -i \u0026#39;/ swap / s/^\\(.*\\)$/#\\1/g\u0026#39; /etc/fstab # 关闭selinux setenforce 0 \u0026amp;\u0026amp; sed -i \u0026#39;s/^SELINUX=.*/SELINUX=disabled/\u0026#39; /etc/selinux/config # 升级Linux内核为最新稳定版（4.44） rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-4.el7.elrepo.noarch.rpm # 安装内核 yum --enablerepo=elrepo-kernel install -y kernel-lt # 设置开机从新内核启动 grub2-set-default \u0026#39;CentOS Linux (4.4.219-1.el7.elrepo.x86_64) 7 (Core)\u0026#39; # 注意:设置完内核后，需要重启服务器才会生效。 #查询内核 uname -r # 调整内核参数，对于k8s cat \u0026gt; kubernetes.conf \u0026lt;\u0026lt;EOF net.bridge.bridge-nf-call-iptables=1 net.bridge.bridge-nf-call-ip6tables=1 net.ipv4.ip_forward=1 net.ipv4.tcp_tw_recycle=0 vm.swappiness=0 vm.overcommit_memory=1 vm.panic_on_oom=0 fs.inotify.max_user_instances=8192 fs.inotify.max_user_watches=1048576 fs.file-max=52706963 fs.nr_open=52706963 net.ipv6.conf.all.disable_ipv6=1 net.netfilter.nf_conntrack_max=2310720 EOF # 将优化内核文件拷贝到/etc/sysctl.d/文件夹下，这样优化文件开机的时候能够被调用  cp kubernetes.conf /etc/sysctl.d/kubernetes.conf # 手动刷新，让优化文件立即生效 sysctl -p /etc/sysctl.d/kubernetes.conf # 调整系统时区  # 设置系统时区为中国/上海 timedatectl set-timezone Asia/Shanghai # 将当前的 UTC 时间写入硬件时钟 timedatectl set-local-rtc 0 # 重启依赖于系统时间的服务  systemctl restart rsyslog systemctl restart crond # 关闭系统不需要的服务 systemctl stop postfix \u0026amp;\u0026amp; systemctl disable postfix # 设置日志保存方式 # 创建保存日志的目录 mkdir /var/log/journal # 创建配置文件存放目录 mkdir /etc/systemd/journald.conf.d # 创建配置文件 cat \u0026gt; /etc/systemd/journald.conf.d/99-prophet.conf \u0026lt;\u0026lt;EOF [Journal] Storage=persistent Compress=yes SyncIntervalSec=5m RateLimitInterval=30s RateLimitBurst=1000 SystemMaxUse=10G SystemMaxFileSize=200M MaxRetentionSec=2week ForwardToSyslog=no EOF # 重启systemd journald的配置  systemctl restart systemd-journald # 打开文件数调整 (可忽略，不执行) echo \u0026#34;* soft nofile 65536\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf echo \u0026#34;* hard nofile 65536\u0026#34; \u0026gt;\u0026gt; /etc/security/limits.conf # kube-proxy 开启 ipvs 前置条件 modprobe br_netfilter cat \u0026gt; /etc/sysconfig/modules/ipvs.modules \u0026lt;\u0026lt;EOF #!/bin/bash modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack_ipv4 EOF ##使用lsmod命令查看这些文件是否被引导 chmod 755 /etc/sysconfig/modules/ipvs.modules \u0026amp;\u0026amp; bash /etc/sysconfig/modules/ipvs.modules \u0026amp;\u0026amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4 docker部署 #  # 安装docker # 环境 yum install -y yum-utils device-mapper-persistent-data lvm2 # 配置稳定的仓库，仓库配置会保存到/etc/yum.repos.d/docker-ce.repo文件中 阿里云yum源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 更新yum安装的相关Docke软件包\u0026amp;安装Docker CE  yum update -y \u0026amp;\u0026amp; yum install docker-ce # 设置docker daemon文件 # 创建/etc/docker目录 mkdir /etc/docker # 更新 daemon.json文件 cat \u0026gt; /etc/docker/daemon.json \u0026lt;\u0026lt;EOF { \u0026#34;exec-opts\u0026#34;:[\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;log-driver\u0026#34;:\u0026#34;json-file\u0026#34;, \u0026#34;log- opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;100m\u0026#34; } } EOF # 注意: 一定注意编码问题，出现错误:查看命令:journalctl -amu docker 即可发现错误 # 创建，存储docker配置文件 mkdir -p /etc/systemd/system/docker.service.d # 重启docker服务 systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart docker \u0026amp;\u0026amp; systemctl enable docker kubeadm #  # 安装kubernetes的时候，需要安装kubelet, kubeadm等包，但k8s官网给的yum源是 packages.cloud.google.com，国内访问不了，此时我们可以使用阿里云的yum仓库镜像。 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装kubeadm、kubelet、kubectl yum install -y kubeadm-1.15.1 kubelet-1.15.1 kubectl-1.15.1 # 启动 kubelet systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet "},{"id":20,"href":"/posts/kubernetes%E4%B8%80/","title":"kubernetes(一)","section":"Posts","content":"pod底层核心原理 #  pause容器共享网络，本地容器相互访问只需要使用localhost来访问，不需要ip地址。\n每一个pod里都有pause容器。\npod内部的容器没有ip地址。\n 创建pod后，会先创建pause容器。pause容器先于业务容器创建。 pause容器用来共享pod中所有容器的网络，存储。 pod中所有容器互相之间的访问，只需要使用localhost访问即可，相当于访问本地服务一样。 一个pod只能在一个物理机上运行，不能分裂。一个物理机上可以部署多个pod。  pod是K8s中的最小单位，一个Pod有一个或多个容器组成。\npod用来做集群，只需要部署多个内容相同的pod。\npod一旦当机，就不存在了（生命周期短）。\nCoreDNS #  为集群中的SVC创建一个域名IP的对应关系解析\nK8s核心资源清单 #    replication controller(RC) \u0026mdash;\u0026ndash;副本控制器：创建与预期设定的副本数量相同的pod副本，且永远保持和预期设定的数量一致。永远保证服务高可用性。\n设置：replicas = 3（要求副本数量是3个）\nreplication controller就必须维护3个副本\n  replica set (RS) \u0026mdash;-副本控制器：功能和replication controller功能一致。\n区别：选择器的功能不一样。RC只支持单选，RS可以支持多选。\nReplicationController: selector支持单选\napp = Myapp\nReplicaSet: selector支持多选\napp = Myapp \u0026amp; name = order\n在新版的Kubernetes中建议使用ReplicaSet来取代ReplicationController\n滚动更新；项目根据需求变更，经常进行发布新的版本，每发布一个新的版本，就需要上线\n pod版本的迭代。  ReplicaSet不支持滚动更新，Deployment资源对象支持pod滚动更新，因此RS通常跟Deployment一起使用。\n  Deployment资源对象 \u0026mdash;\u0026ndash; 部署对象（部署服务，通常都是以deployment对象为准）\n支持滚动更新\n  HPA[HorizontalPodAutoScale] \u0026mdash;\u0026mdash;-支持pod自动扩容（减轻资源利用率，利用率超过80%，重新创建pod）\n扩容,缩容：\n scale replicas = 3  k8s管理pod的多个副本，着多个副本都是一个服务集群。\ntomcat集群，mysql集群都可以使用deployment进行部署吗(使用容器部署)？\n 容器生命周期是短暂的，容器重启，关闭对tomcat服务没有影响。 tomcat服务不存储任何数据（tomcat无状态部署） mysql集群中分master/slave，挂了一台机器后丢失master/slave结构。 同理，deployment的方式也无法管理elasticsearch  数据存储服务不能放在容器中进行部署。数据存储服务有状态服务。\n 容器进程服务，不存储数据，数据存储在磁盘 容器服务都有一个唯一标识id，重新创建一个容器，这个容器就是全新容器，找不到原来那个容器的数据。 集群不可用。  如何解决mysql这样有状态服务也能部署在容器中？？？\n什么叫做有状态， 什么叫做无状态？\n有状态：\n 需要有实时的数据需要存储更新存储 在集群服务网络中，把某一个服务抽离出去，再加入回来，服务没有办法正常工作。  满足以上两点的服务，就叫做有状态服务。\n无状态：\n 没有实时的数据需要存储，或者更新。 在集群服务网络中，把某一个服务抽离出去，再加回来，不影响服务正常运行。  举例子：\n有状态：MYSQL，ES,MQ,redis,zookeeper,kafka，nginx（集群）\u0026hellip;\n无状态：nginx（单机），tomcat，微服务架构项目\nk8s提供了一个组件：StatefullSet，此组件就是用来解决可以在k8s中部署有状态服务。\n  StatefullSet \u0026mdash;\u0026ndash;用来部署有状态服务\n 稳定的持久化存储，pod重新调度后 稳定的网络标识，重新调度后podname和hostname都不变 pod创建是有顺序的，串行化进行    DaemonSet \u0026mdash;\u0026ndash;保证每一个node至少会存在一个pod(除非node节点被打上了污点)\n  Volume \u0026mdash;-挂载卷（数据挂载，数据存储）\n  Label \u0026mdash;-标签（资源对象都可以使用label给打上标签，作为唯一标识）\nrs, deployment,pod, statefullset, daemonset都可以使用标签进行标识。\n有了标签后：通过标签选择器selector，精确选择对应的资源对象，然后对这些资源对象进行相关操作。\n标签格式：键值对。\napp= Myapp\nyaml:\napp: Myapp\n  服务注册与发现 #  pod负载均衡\n网络问题\niptables 负载均衡\nipvs 负载均衡\n集群搭建 #  创建pod：具体需要创建几个资源对象？\n创建pod，实际上必须创建3个资源对象：\n deployment my-nginx ReplicaSet my-nginx-756fb87568 pod my-nginx-756fb87568-jqxcl  kubectl run my-nginx \u0026ndash;image=nginx \u0026ndash;port=80\n含义：根据nginx镜像，创建一个pod，指定端口为80\nmy-nginx是deployment对象的名字\n\u0026ndash;image=nginx是pod内部运行的容器依赖的镜像，此镜像如果本地没有，将会从网络进行下载。\n调度策略：scheduler\n如果版本镜像：nginx:latest \u0026mdash;没有指定特定版本，每次都会从网络下载镜像。\nsvc 的type：\n ClusterIP：虚拟IP，没有在物理机上绑定端口，因此外网无法访问 NodePort：可以在物理机上绑定端口，通过此端口，可以访问内网pod loadBalancer：第三方商家提供的外网访问的组件，阿里云\u0026mdash;花钱  yaml文件不需要自动编写，只需要通过指令，从网络上下载yaml文件\n"},{"id":21,"href":"/posts/postgresql%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7/","title":"postgresql 创建用户及表空间","section":"Posts","content":"进入管理员界面\npsql postgres #创建用户(ROLE) postgres=# create user testuser with password \u0026#39;******\u0026#39;; CREATE ROLE postgres=# create database testdb owner testuser; CREATE DATABASE postgres=# grant all on database testdb to testuser; GRANT postgres=# alter user testuser superuser; ALTER ROLE postgres=# \\du 角色列表 角色名称 | 属性 | 成员属于 -------------+--------------------------------------------+---------- postgres | 超级用户, 建立角色, 建立 DB, 复制, 绕过RLS | {} testuser | 超级用户 | {} postgres=#  "},{"id":22,"href":"/posts/IO%E6%A8%A1%E5%9E%8B/","title":"IO模型讲义","section":"Posts","content":"IO模型讲义 #  用户空间和内核空间 #   用户空间：用户程序使用的内存空间 内核空间：系统内核程序使用的内存空间  PIO与DMA #   PIO 早先的磁盘和内存之间的数据传输要经过CPU存储转发，这种方式成为PIO DMA 后来，DMA（直接内存访问，Direct Memory Access）取代了PIO，它可以不经过CPU而直接进行磁盘和内存（内核空间）的数据交换。  缓存IO和直接IO #  缓存IO：数据从磁盘先通过DMA copy到内核空间，再从内核空间通过cpu copy到用户空间\n直接IO： 数据从磁盘通过DMA copy到用户空间\n"},{"id":23,"href":"/posts/%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E4%BD%BF%E7%94%A8git%E5%91%BD%E4%BB%A4%E4%B8%AD%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E6%80%8E%E4%B9%88%E5%8A%9E/","title":"命令行中使用git命令中文乱码怎么办？","section":"Posts","content":"命令行中使用git命令中文乱码怎么办？ #  git 默认中文文件名是\\xxx\\xxx等八进制形式，是因为对0x80以上的字符进行了转义。\n解决办法是设置core.quotepath为false\ngit config --global core.quotepath false 原因：\n Commands that output paths (e.g. ls-files, diff), will quote “unusual” characters in the pathname by enclosing the pathname in double-quotes and escaping those characters with backslashes in the same way C escapes control characters (e.g. \\t for TAB, \\n for LF, \\\\ for backslash) or bytes with values larger than 0x80 (e.g. octal \\302\\265 for “micro” in UTF-8). If this variable is set to false, bytes higher than 0x80 are not considered “unusual” any more. Double-quotes, backslash and control characters are always escaped regardless of the setting of this variable. A simple space character is not considered “unusual”. Many commands can output pathnames completely verbatim using the -z option. The default value is true.\n 因为 core.quotepath 默认值为 true，git 命令把输出的内容中，存在用双引号引起来的路径名中的“不寻常”（指中文，或大于 0x80 的字节）的字符，用反斜杠进行转转义。\n例如：会把 Tab 转义为 \\t \n"},{"id":24,"href":"/posts/%E7%90%86%E8%AE%BA%E5%9F%BA%E7%9F%B3%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E7%8B%AC%E7%AB%8B%E6%80%A7%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF/","title":"理论基石：条件概率、独立性与贝叶斯","section":"Posts","content":"从概率到条件概率 #  条件概率的发生背景 #  从这一篇开始，我们就正式进入到概率统计的内容板块中了。\n对于概率，相信大家都不会陌生，在各阶段的数学课上，它都是高频出现的常客，最简单的概率场景比如掷骰子：第一次掷出的点数为 5 的概率为多大？你会毫不犹豫的说出答案：16。\n这太简单了。接下来我增加一个限定条件：已知在抛出骰子是奇数的情况下，抛掷点数为 5 的可能性有多大？\n发现了没有，在第二个问题中我就没有直接的只问投掷出 5 这个事件的概率，而是增加了一个前提条件：这次抛掷出的点数为奇数。\n生活中这类场景更多，我们一般不会直接去推断一个事件发生的可能性，因为这样实际意义并不明显，而且也不容易推断出结果。比如我问你今天下雨的概率是多大？你可能是一头雾水，什么地点？什么月份？当日云层的厚度？这些条件都没有提供，这样是无法给出一个有意义、有价值的合理推断的。\n而且在实际情况下，一个事件一般而言也不会是孤立的发生，它会伴随着其他事情一同出现，单独谈一个事件的概率，一般而言也是不存在的。\n因此，在实际的应用中，我们更关心的是条件概率，也就是在给定部分信息的基础上对试验结果的推断。这些给定的信息就是我们附加的条件，是我们研究时关注的重点。\n条件概率的具体描述 #  这里，我们来具体描述一下条件概率：\n假设我们知道给定事件 B 已经发生，在此基础上希望知道另一个事件 A 发生的可能性，此时我们就需要构造出 条件概率，它需要先顾及事件 B 已经发生的信息，然后再求出事件 A 发生的概率。\n这个条件概率描述的就是在给定事件 B 发生的情况下，事件 A 发生的概率，我们专门把它记作：P(A|B)。\n那我们回到投掷骰子的问题中来，在投出奇数点数骰子的前提下，投出 5 的概率有多大？奇数点数一共有 {1,3,5} 三种，其中出现 5 的概率是 13。很明显，和单独问投出点数是 5 的概率计算结果是不同的。\n下面我们来抽象一下条件概率的场景。\n我们再回到最简单、最容易理解的情景下来看，即在古典概率的模式下来分析：假定一个试验有 N 个等可能的结果，事件 A 和 B 分别包含 M1 个和 M2 个结果，这其中有 M12 个结果是公共的，这就是同时发生事件 A 和事件 B，即 A∩B 事件所包含的试验结果数。\n形象的描述一下上述场景，如图所示：\n那我问你，单纯的发生事件 A 和事件 B 的概率是多少？你肯定会脱口而出，分别是 M1N 和 M2N，那进一步到条件概率中来，已知在事件 B 发生的前提条件下，事件 A 发生的概率是多少？\n此时，我们的整体考虑范围由最开始的 N 个全部的可能结果局限到现在的 M2 个结果，即 B 事件发生的结果范围，而这其中只有 M12 个结果对应事件 A 的发生，那么我们不难计算出，条件概率 P(A|B)=M12M2 。\n条件概率的表达式分析 #  为了更加深入地挖掘这里面的内涵，我们进一步对条件概率的表达式 P(A|B)=M12M2 进行展开：\nP(A|B)=M12M2=(M12/N)(M2/N)=P(AB)P(B)\n由此，我们得到了条件概率的一般定义：P(A|B)=P(AB)P(B)。\n两个事件的独立性 #  我们在上面的例子中，进一步进行分析，我们发现事件 A 的无条件概率 P(A) 与其在给定事件 B 发生下的条件概率 P(A|B) 显然是不同的，即 P(A|B)≠P(A) ，而这也是非常普遍的一种情况，这两个概率值一般都存在着差异。\n其实，这反映了两个事件之间存在着一些关联，假如满足 P(A|B)\u0026gt;P(A)，则可以说事件 B 的发生使得事件 A 的发生可能性增大了，即事件 B 促进了事件 A 的发生。\n但是如果 P(A)=P(A|B) 呢，这种情况也是存在的，而且这是一种非常重要的情况，他意味着事件 B 的发生与否对事件 A 发生的可能性毫无影响。这时，我们就称 A , B 这两个事件独立，并由条件概率的定义式进行转换可以得到：\nP(A|B)=P(AB)P(B)⇒P(AB)=P(A|B)P(B)=P(A)P(B)\n实际上，我们拿这个式子来刻画独立性，比单纯使用表达式 P(A)=P(A|B) 要更好一些，因为 P(AB)=P(A)P(B) 这个表达式不受概率 P(B) 是否为 0 的因素制约。\n由此我们说，如果 A 和 B 两个事件满足 P(AB)=P(A)P(B)，则称事件 A 和事件 B 独立。\n从条件概率到全概率公式 #  首先我们假设 B1,B2,B3,\u0026hellip;,Bn 为有限个或无限可数个事件，他们之间两两互斥且在每次试验中至少发生其中一个，我们用图直观的表示如下：\n我们用表达式描述上面这幅图的含义就是：\nBiBj=ϕ\nB1+B2+B3\u0026hellip;+Bn=Ω\n现在我们接着引入另一个事件 A，如下图所示：\n很明显，因为 Ω 是一个必然事件（换句话说就是事件全集），因此有 P(A)=P(AΩ)，进一步进行推导有：P(A)=P(AΩ)=P(AB1+AB2+AB3+\u0026hellip;+ABn)，因为事件 Bi,Bj 两两互斥，显然 AB1,AB2,AB3,\u0026hellip;,ABn 也两两互斥，因此就有：\nP(A)=P(AB1)+P(AB2)+P(AB3)+\u0026hellip;+P(ABn)\n再由条件概率公式 P(ABi)=P(Bi)P(A|Bi) 进行代入，将上式转换得到：\nP(A)=P(B1)P(A|B1)+P(B2)P(A|B2)+\u0026hellip;+P(Bn)P(A|Bn)\n这就是我们最终得到的全概率公式，“全”字的意义在于：全部的概率 P(A) 被分解成了许多的部分概率之和。\n我们再次回过头来看看全概率公式的表达式，我们从式子里可以非常直观的发现：事件 A 的概率 P(A) 应该处于最小的 P(A|Bi) 和最大的 P(A|Bj) 之间，它不是所有条件概率 P(A|Bk) 的算术平均，因为他们各自被使用的机会（即 P(Bi)）各不相同。因此全概率 P(A) 就是各 P(A|Bk) 以 P(Bk) 为权的加权平均值。\n全概率公式的实际价值在于，很多时候，我们直接去计算事件 A 的概率是比较困难的。但是如果条件概率 P(A|Bk) 是已知的，或很容易被我们推导计算时，全概率公式就成了计算概率 P(A) 的很好的途径。\n聚焦贝叶斯公式 #  贝叶斯公式概述 #  了解了全概率公式之后，我们可以进一步的处理条件概率的表达式，得到下面这个式子：\nP(Bi|A)=P(ABi)P(A)=P(Bi)P(A|Bi)P(A)\n=P(Bi)P(A|Bi)P(B1)P(A|B1)+P(B2)P(A|B2)+\u0026hellip;+P(Bn)P(A|Bn)\n这就是大名鼎鼎的贝叶斯公式。\n这个式子你千万不要觉得他平淡无奇，觉得仅仅只是数学式子的推导和罗列。这一个公式里包含了全概率公式、条件概率、贝叶斯准则，我们来挖掘一下里面所蕴藏的最重要的内涵：\n贝叶斯公式将条件概率 P(A|B) 和条件概率 P(B|A) 紧密的联系了起来，其最根本的数学基础就是因为 P(A|B)P(B)=(B|A)P(A)，他们都等于 P(AB)。\n那这里面具体的深刻内涵是什么呢？我们接着往下看。\n本质内涵：由因到果，由果推因 #  现实中，我们可以把事件 A 看成是结果，把事件 B1,B2,\u0026hellip;,Bn 看成是导致这个结果的各种可能的原因。\n那么，我们所介绍的全概率公式 P(A)=P(B1)P(A|B1)+P(B2)P(A|B2)+\u0026hellip;+P(Bn)P(A|Bn) 就是由各种原因推理出结果事件发生的概率，是由因到果。\n但是，更重要、更实际的应用场景是，我们在日常生活中常常是观察到某种现象，然后去反推造成这种现象的各种原因的概率。简单点说，就是由果推因。\n贝叶斯公式 P(Bi|A)=P(ABi)P(A)=P(Bi)P(A|Bi)∑jP(Bj)P(A|Bj)，最终求得的就是条件概率 P(Bi|A)，就是在观察到结果事件 A 已经发生的情况下，我们推断结果事件 A 是由原因 Bi 造成的概率的大小，以支撑我们后续的判断。\n那么我们可以说，单纯的概率 P(Bi) 我们叫做先验概率，指的是在没有别的前提信息情况下的概率值，这个值一般需要借助我们的经验估计得到。\n而条件概率 P(Bi|A)，我们把他叫做是 后验概率，他代表了在获得了信息 A 之后 Bi 出现的概率，可以说后验概率是先验概率在获取了新信息之后的一种修正。\n贝叶斯公式的应用举例 #  比如，贝叶斯公式应用的一个常见例子就是 X 光片的病理推断案例，在某个病人的 X 光片中，医生看到了一个阴影，这就是结果事件 A，我们希望对造成这个结果的三种可能原因（原因 1：恶性肿瘤；原因 2：良性肿瘤；原因 3：其他原因）进行分析判断，推断分属于各个原因的概率，如图所示：\n例如，我们想求出原因是恶性肿瘤的概率，也就是求条件概率：P(B1|A) 的值。\n我们只要知道在这三种原因下出现阴影的概率，也就是 P(A|B1)，P(A|B2)，P(A|B3)，以及三种原因的先验概率：P(B1)，P(B2)，P(B3)，就能通过贝叶斯公式P(B1|A)=P(B1)P(A|B1)P(B1)P(A|B1)+P(B2)P(A|B2)+P(B3)P(A|B3)求得，而上述这些需要我们知道的值，基本上都可以通过历史统计数据得到。\n全文思路梳理 #  这一小节里，我们从概率到条件概率，再到全概率公式，最终聚焦到贝叶斯公式，从概念的层面一路梳理过来，目的是帮助大家迅速形成一套以条件概率为基石的认识世界的视角。理解条件概率的重要性不言而喻，这个概念将贯穿我们整个概率统计专栏体系。\n分享交流 #  我们为本专栏付费读者创建了微信交流群，以方便更有针对性地讨论专栏相关的问题（入群方式请到第 3 篇末尾查看）。\n"},{"id":25,"href":"/posts/%E5%A4%9A%E5%85%83%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%AE%9E%E8%B7%B5%E8%81%9A%E7%84%A6%E5%A4%9A%E5%85%83%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83/","title":"多元随机变量实践：聚焦多元正态分布","section":"Posts","content":"在前两篇中，我们介绍了多元随机变量的有关概念，重点围绕着多元随机变量的联合概率、条件与边缘概率分布以及独立性和相关性，阐述了多元随机变量之间的关系，这些都是多元随机变量重点需要关注和研究的问题。\n在上两篇理论知识的基础之上，我们在这篇文章里以多元正态分布作为实际例子，让大家能够更直观的理解和强化这些概念和方法。\n再谈相关性：基于多元正态分布 #  很简单，我们举一个例子，之前我们介绍过随机变量的正态分布，这里我们引入多元随机变量的正态分布：\n如果向量 Z 由若干个遵从标准正态分布的独立同分布随机变量 Z1,Z2,\u0026hellip;,Zn 组成，那么我们就说向量 Z 遵从 n 元标准正态分布。\n二元标准正态分布 #  为了便于讨论，我们这里主要讨论二元随机变量的情况。由随机变量 X 和 Y 组成的二元标准正态分布中，随机变量 X 和 Y 都服从均值为 0，方差为 1 的标准正态分布，并且随机变量 X 和 Y 之间的协方差为 0。其协方差矩阵为：[1001]。\n我们利用 Python 来生成服从二元标准正态分布的随机变量 X 和 Y，并且通过可视化的方式进行观察。\n代码片段：\nimport numpy as np import matplotlib.pyplot as plt import seaborn seaborn.set() mean = np.array([0, 0]) conv = np.array([[1, 0], [0, 1]]) x, y = np.random.multivariate_normal(mean=mean, cov=conv, size=5000).T plt.figure(figsize=(6, 6)) plt.plot(x, y, 'ro', alpha=0.2) plt.gca().axes.set_xlim(-4, 4) plt.gca().axes.set_ylim(-4, 4) plt.show() 在代码中，我们生成了各自均值为 0，方差为 1，随机变量间的协方差为 0 的二元标准正态分布随机变量 X和 Y，一共生成 3000 组样本，我们实际观察一下可视化的结果。\n运行结果：\n从图中我们发现，在均值点（这里对应的是原点）附近，样本出现的概率较高（我们设置的样本点的透明度为 0.2，因此颜色越深意味着样本点的个数越多）。远离均值点的地方样本出现的概率较低，并且无论向任何方向，总体上概率没有表现出太大区别。\n二元一般正态分布 #  我们通过调整参数，可以逐渐将二元标准正态分布变换为二元一般正态分布。我们可以调整的参数主要有以下三个方面：\n第一：调整多个随机变量自身的均值，这样是让样本整体在二维平面上进行平移，这个很简单，我们就不多说了。\n第二：调整随机变量 X，Y 自身的方差，当然此时我们还是保留他们互相之间彼此独立的关系，我们来观察一下样本图像的特点。\n与标准二元正态分布对照，我们设定随机变量 X2 的方差为 4，Y2 的方差为 0.25，对比观察一下：\n代码片段：\nimport numpy as np import matplotlib.pyplot as plt import seaborn seaborn.set() mean = np.array([0, 0]) conv_1 = np.array([[1, 0], [0, 1]]) conv_2 = np.array([[4, 0], [0, 0.25]]) x_1, y_1 = np.random.multivariate_normal(mean=mean, cov=conv_1, size=3000).T x_2, y_2 = np.random.multivariate_normal(mean=mean, cov=conv_2, size=3000).T plt.plot(x_1, y_1, 'ro', alpha=0.05) plt.plot(x_2, y_2, 'bo', alpha=0.05) plt.gca().axes.set_xlim(-6, 6) plt.gca().axes.set_ylim(-6, 6) plt.show() 运行结果：\n从图中对比可以看出，蓝色的样本点就是调整了随机变量各自的方差，但保持随机变量 X 和 Y 之间协方差为 0 的样本分布。\n第三：就是调整协方差。 我们保持随机变量各自的方差不变，通过改变协方差的值，来观察协方差的变换给随机变量间的相关特性带来的影响以及在图像上的反映。\n代码片段：\nimport numpy as np import matplotlib.pyplot as plt import seaborn seaborn.set() fig, ax = plt.subplots(2, 2) mean = np.array([0,0]) conv_1 = np.array([[1, 0], [0, 1]]) conv_2 = np.array([[1, 0.3], [0.3, 1]]) conv_3 = np.array([[1, 0.85], [0.85, 1]]) conv_4 = np.array([[1, -0.85], [-0.85, 1]]) x_1, y_1 = np.random.multivariate_normal(mean=mean, cov=conv_1, size=3000).T x_2, y_2 = np.random.multivariate_normal(mean=mean, cov=conv_2, size=3000).T x_3, y_3 = np.random.multivariate_normal(mean=mean, cov=conv_3, size=3000).T x_4, y_4 = np.random.multivariate_normal(mean=mean, cov=conv_4, size=3000).T ax[0][0].plot(x_1, y_1, 'bo', alpha=0.05) ax[0][1].plot(x_2, y_2, 'bo', alpha=0.05) ax[1][0].plot(x_3, y_3, 'bo', alpha=0.05) ax[1][1].plot(x_4, y_4, 'bo', alpha=0.05) plt.show() 在代码中，我们生成了四组二元正态分布，其中第一组是作为对照用的二元标准正态分布。第二组的协方差为 0.3，第三组的协方差为 0.85，第四组的协方差为 −0.85。\n运行结果：\n从运行结果中我们发现，与二元标准正态分布的样本图像呈现为圆形相比，协方差不为 0 的二元正态分布呈现为一定斜率的椭圆图像，并且协方差越大，椭圆越窄。\n同时协方差为正和为负，椭圆的方向是相反的，这个很容易理解，分别对应体现了正相关和负相关的关系。\n聚焦相关系数 #  有了生成多元正态分布随机变量的方法和可视化手段之后，我们再来从量化的角度回答前面一个小节中提到过的问题：协方差大的两个随机变量，他们之间的相关性一定就大于协方差小的随机变量吗？\n我们来看下面这段代码。\n代码片段：\nimport numpy as np import matplotlib.pyplot as plt import seaborn seaborn.set() fig, ax = plt.subplots(1, 2) mean = np.array([0,0]) conv = np.array([[1, 0.85], [0.85, 1]]) x_1, y_1 = np.random.multivariate_normal(mean=mean, cov=conv, size=3000).T x_2 = x_1*100 y_2 = y_1*100 ax[0].plot(x_1, y_1, 'bo', alpha=0.05) ax[1].plot(x_2, y_2, 'bo', alpha=0.05) S_1 = np.vstack((x_1, y_1)) S_2 = np.vstack((x_2, y_2)) print(np.cov(S_1)) print(np.cov(S_2)) plt.show() 运行结果：\n[[1.03533866 0.879386 ] [0.879386 1.02916918]] [[10353.38658014 8793.8599675 ] [ 8793.8599675 10291.69181821]] 从代码中，我们首先按照协方差矩阵 [10.850.851] 生成了二元正态分布随机变量 X1 和 Y1，然后将其各自扩大 100 倍，得到新的二元正态分布随机变量 X2 和 Y2。\n通过对各自生成的 3000 个样本点进行计算，发现随机变量 X2 和 Y2 之间的协方差（包括各自的方差）是随机变量 X1 和 Y1 的 10000 倍，满足之前推导过的协方差的数量关系\ncov[X2,Y2] =cov[100X1,100Y1] =E[(100X1−100μ)(100Y1−100v)] =1002E[(X1−μ)(Y−v)]=1002cov[X1,Y1]\n然而，让我们再看两组随机变量的样本图像：\n那么，随机变量 X2 和 Y2 的相关性提升了吗？显然没有。\n那好，一方面说协方差越大，相关性越大；一方面又说，协方差即使大了 10000 倍，相关性也不一定大了。到底听谁的？\n实际上，这并不矛盾，这里主要是要告诉大家，随机变量的量纲选取的不同，会对方差和协方差的结果值带来数值上的影响，这在我们的公式推导中已经反复说明了。\n因此我们需要对随机变量完成标准化，进行缩放处理，具体的方法就是将随机变量除以其标准差即可。其实本质上就是让各个随机变量的方差都回到 1，通过这种方法得到的新指标为：\nρXY=Cov[XσX,YσY]=Cov[X,Y]σXσY=Cov[X,Y]√V[X]√V[Y]\n进行标准化处理之后得到了相关系数，我们就可以放心的使用他来进行随机变量相关性的分析。\n有几个重要的结论希望大家能够牢记：\n第一：经过标准化处理之后的相关系数，他的取值介于 [−1,1] 之间，相关系数为 0，说明随机变量之间相互独立。\n第二：相关系数的绝对值越接近 1，随机变量之间的相关性越强，样本分布图像呈现的椭圆就越窄，如果取到 1，图像收缩为一条直线。\n第三：相关系数为正，随机变量正相关，呈现为右上方倾斜，为负则随机变量负相关，呈现左下方倾斜。\n那我们回到上面的例子中来，计算两组随机变量的相关系数：\n代码片段：\nimport numpy as np mean = np.array([0,0]) conv = np.array([[1, 0.85], [0.85, 1]]) x_1, y_1 = np.random.multivariate_normal(mean=mean, cov=conv, size=3000).T x_2 = x_1*100 y_2 = y_1*100 S_1 = np.vstack((x_1, y_1)) S_2 = np.vstack((x_2, y_2)) print(np.corrcoef(S_1)) print(np.corrcoef(S_2)) 运行结果：\n[[ 1. 0.85250365] [ 0.85250365 1. ]] [[ 1. 0.85250365] [ 0.85250365 1. ]] 程序运行的结果生成的是相关系数矩阵，两组随机变量的协方差虽然相差万倍，但经过标准化处理后，我们得到的相关系数却完全一样，这也从量化的角度证明了他们的相关程度完全一致。\n因此，请大家记住，比较随机变量之间的相关性，只看一个指标：那就是相关系数（而不是盯着协方差的取值），相关系数去除了不同量纲所带来的影响。相关系数的绝对值越大，相关性越强，就这一条就够了。\n独立和相关性的关系 #  最后我们来说说独立和相关这两个概念。就是说：两组随机变量独立性和不相关是不是等价的概念？\n首先我们看看，如果随机变量 X 和 Y 独立，那么他们是否一定不相关？\n是否相关，就扣协方差是否为 0 这个判断标准。如果随机变量 X 和 Y 独立，则有 E[XY]=E[X]E[Y]，那么我们接着计算协方差:\ncov(X,Y)=E[(X−E[X])(Y−E[Y])] =E[XY−XE[Y]−E[X]Y+E[X]E[Y]] =E[XY]−E[X]E[Y]−E[X]E[Y]+E[X]E[Y] =E[XY]−E[X]E[Y]=0\n协方差为 0，满足不相关。\n但反过来，如果随机变量相互之间满足协方差为0，即不相关，那么一定能保证他们之间是独立的么？\n独立性意味着什么，意味着随机变量 X 的出现与否，不提供给随机变量 Y 取值概率额外的信息。\n例如，我们观察下图中分布的八个点：\n我们计算一下随机变量 X 和 Y 的协方差：\n代码片段：\nimport numpy as np X = [-2,-1,-1,0,0,1,1,2] Y = [0,1,-1,2,-2,1,-1,0] S = np.vstack((X, Y)) print(np.cov(S)) 运行结果：\n[[ 1.71428571 0. ] [ 0. 1.71428571]] 我们计算了随机变量 X 和随机变量 Y 的协方差，发现结果为 0。按照定义，它们不相关。\n但是独立性呢？很简单，我们就扣条件概率。随机变量 Y=0 的取值概率为 pY(0)=1/4，而当附加了随机变量 X=2 这个条件之后呢？\n我们发现 pY|X(0|2)=1≠pY(0)，随机变量 X 的出现，给随机变量 Y 的取值概率带来了新的信息，因此随机变量 X 和 Y 显然不独立。\n仔细琢磨一下，协方差的定义是从数字的表示特征和现象进行概况的，而随机变量独立性的定义更触及本质一些：即 X 的取值不会影响 Y 的条件分布，因此独立性的描述意义要更强。\n"},{"id":26,"href":"/posts/%E5%A4%9A%E5%85%83%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E4%B8%8B%E7%8B%AC%E7%AB%8B%E4%B8%8E%E7%9B%B8%E5%85%B3/","title":"多元随机变量（下）：独立与相关","section":"Posts","content":"在这篇文章中，我们开始讨论多元随机变量之间的关系，重点围绕独立性和相关性的概念展开。\n关于独立性的讨论 #  随机变量与事件的独立性 #  在概率统计的最开始部分，探讨过事件独立性的概念，同时我们知道：随机变量的取值，本质上同样也是一个事件，因此不难理解其独立性的概念。\n首先我们讨论随机变量与事件之间的相互独立性。那么回到定义中去，我们可以说他的本质就是事件的发生与否，不会对随机变量的取值提供额外的新信息，这其实就是照搬了事件独立性的概念。如果用条件概率的式子来表示的话，就有：\n如果随机变量 X 独立于事件 A，那么满足：\nP({X=x}且A)=P({X=x})P(A)=PX(x)P(A)，对随机变量 X 的一切取值 X=x 都成立。\n同时我们再拿出一个联合概率和条件概念的关系式：\nP({X=x}且A)=PX|A(x)P(A)\n我们把上下这两个式子结合起来看，就有了：\nPX(x)P(A)=PX|A(x)P(A)⇒PX(x)=PX|A(x)\n因此，PX(x)=PX|A(x) 对于随机变量 X 的一切取值恒成立，就是随机变量 X 和事件 A 满足独立性的等价条件，即无条件分布列和条件分布列完全相等。\n随机变量之间的独立性 #  这个时候，如果我们把上面的事件 A 看成是另一个随机变量 Y 的取值，就能顺手得到了随机变量 X 和随机变量 Y 之间相互独立需要满足的条件：\n即：PX,Y(x,y)=pX(x)pY(y)，对于任意的取值 x 和取值 y 都成立，换言之，也就是事件 {X=x} 和 {Y=y} 相互独立。\n然后再通过条件概率和联合概率的式子 pX,Y(x,y)=pX|Y(x|y)pY(y) 进行转换，最终我们就得到了：\npX|Y(x|y)=pX(x) 对于一切取值 x 和满足 pY(y)\u0026gt;0 的取值 y 都成立。\n其实道理也是一样的，独立性意味着随机变量 Y 的取值，不会给随机变量 X 的取值提供任何额外的信息。\n独立性的实际举例 #  我们来实际举个例子看一看，下面这个表格就是随机变量 X 和 Y 的联合分布列。\n我们来检验一下，首先我们计算：\npX(2)=1/20+1/20+0+2/20=4/20\n然后，我们引入 {Y=3} 这个随机变量取值的事件条件，很显然我们发现：\npX|Y(2|3)=P(X=2|Y=3)=0\n显然，pX(2)≠pX|Y(2|3)，不满足随机变量之间相互独立的条件。\n条件独立的概念 #  同条件概率一样，很多情况下我们需要在一些特定事件发生的条件下来讨论随机变量之间的独立性，这个在实际的应用当中很有意义。\n如果说随机变量 X 和 Y 满足事件 A 成立下的条件独立，定义实际上很简单。就是在之前的定义式的每一个部分都添加一个事件条件 A，即对于一切取值 x 和 y，都满足 P(X=x,Y=y|A)=P(X=x|A)P(Y=y|A) 的等式成立。\n同样的，最终我们还是可以转换成类似之前条件概率和无条件概率的等价形式：\npX|Y,A(x|y)=pX|A(x)，对于一切 x 和满足 pY(y)\u0026gt;0 的 y 成立。\n我们还是用上面的那个联合分布列来举例，只不过这次我们设定一个条件事件，即事件 A 为 {X≥3且Y≥3}，对应到上面那幅图上，就是我们只探讨阴影范围内的随机变量的独立性：\n显然此处，p3|Y,A(3|y)=p3|A(3)，p4|Y,A(4|y)=p4|A(4) 对于随机变量 Y 的取值 Y=3 或 Y=4 都成立。\n因此，原本并不满足相互独立的随机变量 X 和随机变量 Y，在事件 A 的条件下，随机变量 X 和随机变量 Y满足条件独立。看来条件独立和独立不是等价的概念，这个大家一定要注意。\n独立随机变量的期望和方差 #  从两个随机变量谈起 #  接着，我们在这里看一个很重要的结论，如果随机变量 X 和随机变量 Y 之间相互独立，他们之间的期望就应该满足这么一个关系：\nE[XY]=E[X]E[Y]\n这个结论乍一看上去比较直观，但怎么具体证明一下，把里面的道理说清楚呢？那我们还得回到定义中去：\nE[XY]=∑x∑yxypX,Y(x,y)\n关键就在这里，由于随机变量之间满足独立性，则他们的联合分布列和边缘分布列之间满足：\npX,Y(x,y)=pX(x)pY(y)\n因此，我们替换一下，就有\nE[XY]=∑x∑yxypX,Y(x,y) =∑x∑yxypX(x)pY(y) =∑xxpX(x)∑yypY(y) =E[X]E[Y]\n我们只看头尾，得到结论为：E[XY]=E[X]E[Y]。\n那么方差这个指标呢？我们主要观察相互独立的随机变量 X 和随机变量 Y 的和，即：X+Y 的方差。为了操作方便，我们这里对随机变量 X 和 Y 进行一下预处理，将它们进行平移、去中心化，使得随机变量的期望变为 0，但是方差仍然能保持不变：\n~X=X−E[X]，则此时满足 E[~X]=0。\n同理我们也对随机变量 Y 进行类似处理：\n~Y=Y−E[Y]，满足 E[~Y]=0\nvar(X+Y)=var(~X+~Y)，我们按照方差的定义进行展开：\nvar(~X+~Y)=E[(~X+~Y−E[~X+~Y])2]\n由于 E[~X+~Y]=E[~X]+E[~Y]=0\n因此我们有：\nE[(~X+~Y−E[~X+~Y])2]=E[(~X+~Y)2]=E[~X2+~Y2+2~X~Y]=E[~X2]+E[~Y2]+2E[~X~Y]\n由于随机变量 X 和随机变量 Y 之间满足独立性，则：\nE[~X~Y]=E[~X]E[~Y]=0\n因此有：\nE[~X2]+E[~Y2]+2E[~X~Y] =E[~X2]+E[~Y2]\n=E[(~X−E[~X])2]+E[(~Y−E[~Y])2] =var[~X]+var[~Y]\n=var[X]+var[Y]\n最终就顺利的推理出了独立的随机变量 X 和 Y 满足：\nvar[X+Y]=var[X]+var[Y]\n最后我们再总结一下：\n随机变量 X 和随机变量 Y 之间满足：E[XY]=E[X]E[Y] 以及 var[X+Y]=var[X]+var[Y] 的前提条件是随机变量之间满足独立性。而 E[X+Y]=E[X]+E[Y] 成立，则不需要任何前提条件。\n扩展到两个以上随机变量 #  我们假设有三个随机变量 X、Y、Z，如果他们之间满足：\npX,Y,Z(x,y,z)=pX(x)pY(y)pZ(z)，对于一切的随机变量的取值 x、y、z 都成立，则我们称这三个随机变量 X、Y、Z 是相互独立的。\n同理，多个相互独立的随机变量的和的方差满足：\nvar[X+Y+Z]=var[X]+var[Y]+var[Z]\n请大家注意，这个式子非常有用，独立随机变量的和会出现在许多实际的应用场合，这个我们先按下不表，后面的相关章节中会仔细分析。\n随机变量的相关性分析 #  如何量化相关程度 #  上面讲的独立性，我们仅讨论随机变量之间是否独立，但是并不关心或者说并没有深入探究随机变量之间的具体关系。而现在我们具体通过量化来衡量多元随机变量之间的相关程度，即当某一个变量改变时，其他变量将发生多大的变化。\n强调一下多元随机变量之间的关系，我们讨论随机变量 X 和随机变量 Y 之间的关系，是严格的配对关系，例如随机变量 X=xk 时，必然有固定的随机变量 Y=yk 取值与之配对，因此二元随机变量的分布可以以二维坐标的形式，在平面上进行散点图的可视化表示，这个我们在后面的内容中将会看到。\n下面我们进一步探讨随机变量 X 和随机变量 Y 之间的关系，如果他们之间存在着某种关系，我们一般比较关心他们之间的关系的“紧密”程度，或者说是相互间变化的“趋势”，所谓趋势，我们说直白通俗点，就是随着 X取值的变大，随机变量 Y 的取值是趋于变大还是变小。\n运用协方差的概念 #  那么具体对随机变量 X 和随机变量 Y 进行上述关系定量分析的指标就是我们下面要介绍的协方差，随机变量 X 和 Y 的协方差我们定义为：\ncov(X,Y)=E[(X−E[X])(Y−E[Y])]\n这是从数据分布的总体上进行分析，如果计算出来的协方差结果为正，则随机变量 X 和 Y 有相同的变化趋势，简单点说就是随着随机变量 X 增大，随机变量 Y 整体上也随之变大。\n这里我们再啰嗦一点，就是不一定当随机变量 X 的每一个取值变大时，随机变量 Y 的对应取值都变大。但是我们看的是期望，是整体，因此只要大部分取值保持正相关，就能保证协方差公式整体计算结果为正。整体上随机变量 X 和 Y 就保持正相关，因此我们这么说可能更好理解。当随机变量 X 的取值大于期望值时，随机变量 Y 的取值大于期望值的概率也将增大。\n反之，如果协方差的结果为负，则恰好相反，表示当一方增大时，另一方反而倾向于减小，随机变量 X 和 Y呈现负相关。\n协方差结果如果为 0，则表示随机变量 X 和 Y 不相关，即当一方增大时，另一方并不会因此表现出增大或减小的趋势，随机变量 X 和 Y 不具有相关性。\n为多元变量引入协方差矩阵 #  假设此时我们将随机变量的个数由两个拓展到 n 个：X1,X2,X3,\u0026hellip;,Xn，那我们如何来分析随机变量之间的相关性呢？答案很简单，两两计算所有随机变量对 Xi 和 Xj 之间的协方差。\n方差公式也可以统一到协方差公式中来，换句话说随机变量与自身的“协方差”，在公式中反映的就是方差。\n因此，我们可以将上述结果放在一个矩阵中，也就是我们标题中所说的协方差矩阵。第 i 行、第 j 列表示的就是随机变量 Xi 和随机变量 Xj 的协方差，对角线上的元素，表示的就是随机变量 Xi 的方差：\n⎡⎢⎣V[X1]Cov[X1,X2]Cov[X1,X3]Cov[X2,X1]V[X2]Cov[X2,X3]Cov[X3,X1]Cov[X3,X2]V[X3]⎤⎥⎦\n由 Cov[Xi,Xj]=Cov[Xj,Xi] 可知，协方差矩阵是一个对称矩阵。\n相关系数的概念 #  说到这里，我们拿两组随机变量做对比，X 和 Y，以及 Z 和 W，我们通过计算得到两个协方差的计算结果：cov[X,Y] 以及 cov[Z,W]。\n如果两个协方差的计算结果都为正，我们可以说随机变量 X 和 Y 呈正相关，Z 和 W 也呈正相关，这个没有问题，我们前面已经讲过。但是倘若满足 cov[Z,W]\u0026gt;cov[X,Y]，我们能够直接说随机变量 Z 和 W 的相关性大于 X 和 Y 吗？\n我们不忙着拿结论，先看下面这套推理：\n假如说随机变量 Z 和 W 满足和 X 和 Y 之间的倍数关系，即：Z=aX，W=aY，同时随机变量 X 和 Y的期望有：E[X]=μ，E[Y]=v。\n于是按照协方差的定义，就有下面的一系列展开：\ncov[Z,W]=cov[aX,aY] =E[(aX−aμ)(aY−av)] =a2E[(X−μ)(Y−v)] =a2cov[X,Y]\n可以看到，经过严格的推导，我们发现了随机变量 Z 和 W 之间的协方差是 X 和 Y 协方差的 a2 倍，但是，随机变量 Z 和 W 之间的相关性较之 X 和 Y 有变化吗？显然是没有的。\n小结 #  在本篇文章中，我们基快速罗列了多元随机变量独立与相关的理论概念。有些同学可能会觉得不太直观，甚至有些枯燥，那么为了进一步深刻的揭示这些概念的内涵，便于大家理解，我们在下一篇里会以多元正态分布为例进行更多的案例分析。\n"},{"id":27,"href":"/posts/%E5%A4%9A%E5%85%83%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E4%B8%8A%E8%81%94%E5%90%88%E8%BE%B9%E7%BC%98%E4%B8%8E%E6%9D%A1%E4%BB%B6/","title":"多元随机变量（上）：联合、边缘与条件","section":"Posts","content":"试验中引入多个随机变量 #  前两篇我们讨论的离散型和连续型随机变量都是单一变量，然而在现实当中，一个试验常常会涉及到多个随机变量。所谓多个随机变量是指在同一个试验结果之下产生的多个随机变量。这些随机变量的取值是由试验结果确定的，因此它们的取值会存在相互关联。这里我们先以离散型随机变量为例，将离散型随机变量的分布列和期望推广到多个随机变量的情况，并且进一步在此基础上讨论多元随机变量条件和独立的重要概念。\n好了，此刻我们假设试验中不再只有一个随机变量，而是两个随机变量 X 和 Y，同时描述他们俩的取值概率，我们用什么方式？\n联合分布列 #  基于之前讲过的离散型随机变量分布列的概念，这里为多元随机变量引入联合分布列，用 pX,Y 对其进行表示。设 (x,y) 是随机变量 X 和 Y 的一组可能取值。因此对应的 (x,y) 的概率质量就定义为事件 {X=x,Y=y} 的概率：\nPX,Y(x,y)=P({X=x,Y=y})，也就是同时满足事件 {X=x} 和 {Y=y} 的概率。那么首先，来实际看一个联合分布列的表示。很明显，我们可以用一个二维表格来表示随机变量 X 和 Y 的联合分布列：\n从这张表出发，就可以把联合分布列中所有的知识点都梳理一遍：\n第一，可以从图中获得随机变量 X 和 Y 的任意一组取值的联合概率，例如：PX,Y(x3,y2)=P(X=x3,Y=y2)=3/20\n第二，对于由随机变量 X 和 Y 构成的任意事件集合也是一样的，例如定义事件集合 A={(x1,y2),(x3,y2),(x4,y4)}，那么很显然，我们直接就能从联合分布列中计算出事件集合的总概率：\nP((X,Y)∈A)=∑(x,y)∈ApX,Y(x,y)=1/20+3/20+1/20=5/20\n第三，也是最朴实的一点，我们把二维表中所有的联合概率进行相加，得到的结果必然是 1，这也满足概率的归一性。\n边缘分布列 #  如果我们把事件集合再设置的讲究一些，例如把事件集合 A 设置为表中的第一列，即 A={(x1,y1),(x1,y2),(x1,y3)}，此时我们计算出来的事件集合 A 的总概率也就是概率 pX(x1)=P(X=x1)，对于这个概率，我们把它称为边缘概率：\nPX(x1)=1/20+1/20+1/20+0=3/20\n当然，更进一步，如果我们把随机变量 X 所有取值的边缘概率都计算出来，就能得到随机变量 X 的边缘分布列：\npX(x)=P(X=x)=∑yP(X=x,Y=y)=∑yPX,Y(x,y)\n看着公式头疼对吧，简单点，我们先求随机变量 X 每一个取值的边缘概率，就是把对应列的联合概率全部相加，然后再把 X=xi 的所有边缘概率放在一起，就是随机变量 X 的边缘分布列。\n|取值 | x1 | x2 |x3|x4| |\u0026mdash;|\u0026mdash;|\u0026mdash;|\u0026mdash;|\u0026mdash;| | PX(x) | 320 | 320 | 820 | 620 |\n当然，随机变量 Y 的边缘分布也是同理：\npY(y)=P(Y=y)=∑xP(X=x,Y=y)=∑xPX,Y(x,y)\n这里我们就不再赘述了。\n边缘概率和边缘分布列的 “边缘” 是什么含义？一句话描述就是，随机变量 X 的边缘分布列及其任意一个边缘概率的取值，都是只与自己有关，而与其他的随机变量（这里是随机变量 Y）无关了。\n而对应的联合分布列和联合概率中的联合二字，意思也很明显，这里面的取值需由所有的随机变量，即由随机变量 X 和 Y 共同决定。\n条件分布列 #  在前面我们学习了，条件可以给某些事件提供补充信息，由于随机变量的取值也是一种事件。同样的，条件也可以对随机变量取某些值提供补充信息。因此我们是不是能引入随机变量的条件分布列呢？当然是可以的。\n条件可以指某个事件的发生，当然也可以包含其他随机变量的取值。\n还是来看一个风格上我们非常熟悉的图：\n可以发现，在某个事件 A 发生的情况下，随机变量 X 发生的条件分布列很容易给出，还记得条件概率的表达式么，把它拿过来直接套用过来就可以了。\npX|A(x)=P(X=x|A)=P({X=x}∩A)P(A)\n感觉是不是很熟悉？但是有些关键点我还是要再提一下，首先对于随机变量 X 不同的取值 x1,x2,x3,\u0026hellip;,xn，{X=x}∩A 彼此之间互不相容，并且他们的并集是整个事件 A，当然上面的示意图里。随机变量 X 的取值没有完全覆盖事件 A，因为这只是一个示例而已，没有画完全。\n对于这个事件 A，我们知道，它既可以对应某个事件的发生，也可以对应另外一个随机变量的具体取值。我们这里重点讨论给定另一个随机变量值的前提下的条件概率。\n我们还是回到试验中，试验中有两个随机变量 X 和 Y，我们假定的条件就是随机变量 Y 已经取定了一个具体的值 y，那么意味着，这个 y 值的选取可能会提供关于随机变量 X 取值的部分信息。反映在我们的条件分布列 pX|Y 中，对应来看条件分布列中的事件 A 就是随机变量的取值 {Y=y}。\n那么好，此时关键部分就来了，我们把上面的条件分布列的定义式 pX|A(x)=P(X=x|A)=P({X=x}∩A)P(A)中的条件事件 A，替换成随机变量的取值 Y=y，就有了：\npX|Y(x|y)=P(X=x|Y=y)=P(X=x,Y=y)P(Y=y)=PX,Y(x,y)pY(y)\n通过这个公式，我们可以把 {Y=y} 条件下，随机变量 X 所有取值的条件概率都计算出来，就得到了在事件 {Y=y} 之下的随机变量 X 的条件分布列。\n最关键的其实不是这个式子，大家有没有回想起第一篇中我们重点分析过的贝叶斯公式，同样的我们把上面的式子整理一下，有：\npX,Y(x,y)=pY(y)pX|Y(x|y)\npX,Y(x,y)=pX(x)pY|X(y|x)\n这组公式非常重要，他把多个随机变量的联合概率、边缘概率和条件概率这三个概念非常完美的结合在了一起，串联了我们这节的核心内容。\n我们还是举上面的例子，具体对其进行计算验证：\n我们来看看满足 {Y=y2} 的条件下，随机变量 X 的条件分布列：\n首先计算边缘概率 pY(y2)=1/20+1/20+3/20+2/20=7/20\npX|Y(x1|y2)=pX,Y(x1,y2)pY(y2)=1/207/20=1/7\npX|Y(x2|y2)=pX,Y(x2,y2)pY(y2)=1/207/20=1/7\npX|Y(x3|y2)=pX,Y(x3,y2)pY(y2)=3/207/20=3/7\npX|Y(x4|y2)=pX,Y(x4,y2)pY(y2)=2/207/20=2/7\n结合起来，我们就能观察出他的条件分布列：PX|Y(x|y2)：\n| 取值| x1 | x2 |x3|x4| |\u0026mdash;|\u0026mdash;|\u0026mdash;|\u0026mdash;|\u0026mdash;| | PX(x) | 17 | 17 | 37 | 27 |\n我们把这个条件分布列的所有项进行相加，得到的结果为 1，当然也必须为 1 ，满足归一化的条件和要求。\n集中梳理核心的概率理论 #  谈到这里，我们觉得有必要停一停了，结合前面和这一节中所讲过的内容，将条件概率、联合概率、边缘概率、全概率、贝叶斯定理等内容，集中做一个梳理。\n从条件概率及归一性起步 #  实际上，条件分布和无条件分布基本上是一样的，唯一的差别就是条件分布存在一个事件发生的前提，其余的定理都是一样的，我们来一步一步的回顾、演进。\n在这幅图当中，我们绘制出了随机变量 X 构成的一个样本空间，其中 A 为其中发生的某事件。从这里，我们就得到了随机变量 X 在给定事件 A 发生的条件下的条件分布列：\npX|A(x)=P(X=x|A)\n由概率的归一性原则，我们就能够得到：∑xpX|A(x)=1。\n样本划分：条件概率、联合概率推进到边缘概率 #  我们进一步对样本空间做一个划分，让互不相容的事件 A1，A2，A3, A4 成为整个样本空间的一个分割。\n基于上面这幅图，我们有 pX(x)=∑ni=1P(Ai)pX|Ai(x)。\n这个式子很简单，就是一个联合概率到边缘概率的一个转换关系。大家如果觉得理解还有些困难，那是因为中间省掉了一步条件概率和联合概率的转换关系，我们把他添加进去就豁然开朗了。\npX(x)=∑ni=1P(Ai∩{X=x})=∑ni=1P(Ai)pX|Ai(x)\n更进一步：在划分中再引入条件 #  好的，我们再继续往下走，我们在样本空间中给随机变量 X 的取值增加一个条件事件 B，同时为了展示方便，我们要求 P(B∩Ai)\u0026gt;0\n这里再把条件事件 B 掺和进去，看上去大家会觉得很复杂，我们先看结论：\npX|B(x)=∑ni=1P(Ai|B)pX|Ai∩B(x)\n看到规律没，我们在事件 B 的发生条件下讨论事件 {X=x} 发生的概率。那么式子的每一个组成部分都添加上条件 B 即可，等式依然是成立的，就得到了结果表达式。\n总结整合 #  因为这条知识线索实在是太重要了，我们最后不厌其烦，多费口舌，再把条件概率、联合概率、边缘概率反映在一组等式中，一把看个明白：\npX,Y(x,y)=pY(y)pX|Y(x|y)\npX(x)=∑ypY(y)pX|Y(x)\n可以这么说，为什么我反反复复提了三遍这组公式，因为我觉得他在简单的形式下，包含的信息量太大了。而且关键是，他的重要性不言而喻，后续在随机过程等主题中，随处可见，不可不察啊。\n条件期望与全期望 #  条件期望的概念 #  最后，我们再提一下条件期望和全期望的问题。\n条件期望和期望本质上没有任何不同，只不过用来表示权重的概率变成了条件概率而已：\nE[X]=∑xxp(x)\nE[X|A]=∑xxpX|A(x)\n同样，把条件事件 A，替换成随机变量的取值 {Y=y}，就有：\nE[X|Y=y]=∑xxpX|Y(x|y)\n全期望的概念和公式 #  我们再来看一个全期望的概念，也是基于样本空间中的一组分割 A1，A2，A3，A4，我们基于期望的定义公式，通过全概率公式做一步变换可以得到：\nE[X]=∑xxpX(x)=∑xx∑ni=1P(Ai)pX|Ai(x|Ai)=∑ni=1P(Ai)∑xxpX|Ai(x|Ai)=∑ni=1P(Ai)E[X|Ai]\n去掉中间的推导过程，只看一头一尾就有：\nE[X]=∑ni=1P(Ai)E[X|Ai]\n当然，如果我们的事件 A 对应的是随机变量 Y 的取值，简单做一下替换即可：\nE[X]=∑yPY(y)E[X|Y=y]\n由全期望再回到条件期望 #  最后，还是那句话，有了分割 A1，A2，A3，A4，是不是觉得不掺和进去个条件事件 B 就颇感遗憾？是的，我们最后看一下基于事件 B 的条件期望：\n我们来看看怎么把分割和条件都表达进去，来得出条件期望 E[X|B]？很简单，我们从全期望公式出发：\nE[X]=∑ni=1P(Ai)E[X|Ai]\n每一部分都加上条件事件 B，就 ok 了。\nE[X|B]=∑ni=1P(Ai|B)E[X|Ai∩B]\n小结 #  大家仔细揣摩一下，会发现这里面用一根很清晰的线条，把事件、随机变量、条件概率、全概率、边缘概率、条件期望、全期望、贝叶斯全部串联了起来，在这个视图下纵览全局，你会感觉有一种一览众山小的快感。\n"},{"id":28,"href":"/posts/%E8%BF%9E%E7%BB%AD%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%88%86%E5%B8%83%E4%B8%8E%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/","title":"连续型随机变量：分布与数字特征","section":"Posts","content":"在上一篇里，介绍了离散型随机变量，实际上，取值于连续区域的随机变量的应用领域也是十分普遍的。比如汽车行驶的速度、设备连续正常运行的时间等，这些在实际应用中都非常广泛，连续型随机变量能够刻画一些离散型随机变量无法描述的问题。\n概率密度函数 #  在连续型随机变量的讨论范围中，随机变量由离散的变为了实轴上的连续值，那么与离散型随机变量的分布列以及 PMF 函数相对应，我们就有了连续型随机变量相类似的新概念：概率密度函数 PDF，二者在概念上是完全相对应的。\n我们回顾一下前面在讲离散型随机变量分布列时所使用的一张图：\n通过将三个事件所对应的概率值进行相加，就能得到这个事件集合所对应的总的概率：\nP(X∈S)=∑x∈SpX(x)=PX(1)+PX(2)+PX(3)\n而连续型随机变量和离散型随机变量最明显的不同点是，连续型随机变量的个数是无限的、不可数的，不是像这样直接简单相加，而是在实轴的区间范围内，对概率密度函数进行积分运算。\n这里，我们要对概率密度函数的特殊性进行强调：\n第一：实数轴上单个点的概率密度函数 PDF 取值 fX(x) 不是概率，而是概率律，因此他的取值是可以大于 1 的。\n第二：连续型随机变量的概率，我们一般讨论的是在一个区域内取值的概率，而不是某个单点的概率值。实际上，在连续区间内讨论单个点是没有意义的。\n连续型随机变量区间概率的计算 #  连续型随机变量在一个区间内取值的概率，我们可以通过求积分来计算解决。例如上图中，随机变量在 [a,b]区间内的概率即为：P(a≤X≤b)=∫bafX(x)dx，也就是图中阴影区间内的面积。因此这也进一步印证了上面的第二条结论，也就是说我们关注的不是单个点而是一个取值区间的概率计算。\n当 x=a 时，有 P(a≤X≤a)=∫aafX(x)dx=0，因此区间两端是否取等也无关紧要了：\nP(a≤X≤b)=P(a\u0026lt;X≤b)=P(a≤X\u0026lt;b)=P(a\u0026lt;X\u0026lt;b)\n同样的，我们继续进行类比，连续型随机变量概率的非负性和归一性体现在：\n非负性：对一切的 x 都有 fX(x)≥0；\n而归一化体现在 P(−∞≤X≤∞)=∫∞−∞fX(x)dx=1\n连续型随机变量的期望与方差 #  大家千万不要到了这个连续型的新场景下就慌了手脚。在离散型随机变量中，我们通过分布列，求得加权的均值，即获得了离散型随机变量的期望。\n那么在连续型随机变量的场景下，我们死抠定义，期望 E[X] 的核心要义是大量独立重复试验中，随机变量 X 取值的平均数，那么我们此时将分布列替换成概率密度函数 PDF，求和替换成求积分就可以了，即：\nE[X]=∫∞−∞xfX(x)dx\n方差也是一样，扣定义：方差是随机变量到期望的距离平方的期望：\nV[X]=E[(X−E[X])2]=∫∞−∞(x−E[X])2fX(x)dx\n接下来和上一节一样，我们来看几个非常重要的连续型随机变量的实际举例。\n正态分布及正态随机变量 #  正态分布是连续型随机变量概率分布中的一种，你几乎能在各行各业中看到他的身影，自然界中某地多年统计的年降雪量、人类社会中比如某地高三男生平均身高、教育领域中的某地区高考成绩、信号系统中的噪音信号等，大量自然、社会现象均按正态形式分布。\n正态分布中有两个参数，一个是随机变量的均值 μ，另一个是随机变量的标准差 σ，他的概率密度函数 PDF 为：fX(x)=1√2πσe−(x−μ)2/(2σ2)。\n当我们指定不同的均值和标准差参数后，就能得到不同正态分布的概率密度曲线，正态分布的概率密度曲线形状都是类似的，他们都是关于均值 μ 对称的钟形曲线，概率密度曲线在离开均值区域后，呈现出快速的下降形态。\n这里，我们不得不专门提一句，当均值 μ=0，标准差 σ=1 时，我们称之为标准正态分布。\n还是老规矩，眼见为实，下面来观察两组正态分布的概率密度函数取值，一组是均值为 0，标准差为 1 的标准正态分布。另一组，我们取均值为 1，标准差为 2。\n代码片段：\nfrom scipy.stats import norm import matplotlib.pyplot as plt import numpy as np import seaborn seaborn.set() fig, ax = plt.subplots(1, 1) norm_0 = norm(loc=0, scale=1) norm_1 = norm(loc=1, scale=2) x = np.linspace(-10, 10, 1000) ax.plot(x, norm_0.pdf(x), color='red', lw=5, alpha=0.6, label='loc=0, scale=1') ax.plot(x, norm_1.pdf(x), color='blue', lw=5, alpha=0.6, label='loc=1, scale=2') ax.legend(loc='best', frameon=False) plt.show() 运行结果：\n这里，我多一句嘴，在构造正态分布时，均值用参数 loc 来描述，方差用参数 scale 来描述。\n同样的，我们还可以通过基于指定分布的重复采样，来观察和验证模拟试验的情况。\n代码片段：\nfrom scipy.stats import norm import matplotlib.pyplot as plt import numpy as np import seaborn seaborn.set() norm_rv = norm(loc=2, scale=2) norm_rvs = norm_rv.rvs(size=100000) x = np.linspace(-10, 10, 1000) plt.plot(x, norm_rv.pdf(x), 'r', lw=5, alpha=0.6, label=\u0026quot;`$\\\\mu$=2,$\\\\sigma=2$`\u0026quot;) plt.hist(norm_rvs, normed=True, bins=50, alpha=0.6, edgecolor='k') plt.legend() plt.show() 运行结果：\n指数分布及指数随机变量 #  我们再来看看我们要讲的第二种连续型随机变量，指数随机变量。指数随机变量的用处非常广泛，他一般用来表征直到某件事情发生为止所用的时间。\n比如，从现在你观察的时间开始算起，一台仪器设备的使用寿命终止还剩的时间、一个灯泡直到用坏了还剩的时间、陨石掉入地球沙漠还需要的时间等。\n指数随机变量 X 的概率密度函数为：\nfX(x)={λe−λxx≥00其他\n其中，指数分布的参数是 λ，且必须满足 λ\u0026gt;0，指数分布的图形特征是当随机变量 X 超过某个值时，概率随着这个值的增加而呈指数递减。讨论指数分布的概率特性时，我们一般着重注意三个方面的内容：\n第一个：随机变量 X 超过某个指定值 a 的概率，当然此处需要满足 a≥0。依照定义，我们有：P(X≥a)=∫∞aλe−λxdx=e−λa\n第二个：随机变量 X 位于区间 [a,b] 内的概率，实际上也很简单： P(a≤X≤b)=P(X≥a)−P(X≥b)=e−λa−e−λb\n第三个：也就是整个指数分布的数字特征，同时也包含参数 λ 的物理含义。我们在这里可以通过期望和方差的定义，直接用积分求得，这里就不多赘述，直接拿出结论：E[X]=1λ，V[X]=1λ2\n最后，我们还是来实际看看代码。\n代码片段：\nfrom scipy.stats import expon import matplotlib.pyplot as plt import numpy as np import seaborn seaborn.set() x = np.linspace(0, 10, 1000) expon_rv_0 = expon() plt.plot(x, expon_rv_0.pdf(x), color='r', lw=5, alpha=0.6, label='`$\\\\lambda$`=1') expon_rv_1 = expon(scale=2) plt.plot(x, expon_rv_1.pdf(x), color='b', lw=5, alpha=0.6, label='`$\\\\lambda$`=0.5') plt.legend(loc='best', frameon=False) plt.show() 运行结果：\n这里，我们来讲解一下代码，代码的第 8 行和第 10 行，我们分别生成了不同参数的两个指数分布。\n其中，第 8 行，默认参数为 scale=1，而第 10 行里指定 scale=2，在这里 scale 参数和指数分布参数 λ的关系为 scale=1λ，因此 expon_rv_0 是服从参数 λ=1 的指数分布，而 expon_rv_1 是服从参数 λ=0.5 的指数分布。\n最后，我们再来对指数型随机变量进行采样生成，我们采样的是服从参数 λ=1 的指数分布。\n代码片段：\nfrom scipy.stats import expon import matplotlib.pyplot as plt import numpy as np import seaborn seaborn.set() x = np.linspace(0, 10, 1000) expon_rv = expon() expon_rvs = expon_rv.rvs(100000) plt.plot(x, expon_rv.pdf(x), color='r', lw=5, alpha=0.6, label='`$\\\\lambda$`=1') plt.hist(expon_rvs, color='b', normed=True, alpha=0.6, bins=50, edgecolor='k') plt.legend(loc='best', frameon=False) plt.show() 运行结果：\n均匀分布 #  其实，我们还遗漏了一个很重要的分布，它太简单以至于我们时常将他忘记。但是实际上，它在程序中出现的次数，丝毫不少于正态分布和指数分布，这就是我们接下来要介绍的均匀分布。\n代码片段：\nfrom scipy.stats import uniform import matplotlib.pyplot as plt import numpy as np import seaborn seaborn.set() x = np.linspace(-1, 3.5, 1000) uniform_rv_0 = uniform() uniform_rv_1 = uniform(loc=0.5, scale=2) plt.plot(x, uniform_rv_0.pdf(x), color='r', lw=5, alpha=0.6, label='[0,1]') plt.plot(x, uniform_rv_1.pdf(x), color='b', lw=5, alpha=0.6, label='[0.5,2.5]') plt.legend(loc='best', frameon=False) plt.show() 运行结果：\n我们这里只说明一点，在构造均匀分布时，我们传入了两个参数，loc 和 scale。它指的是随机变量 X 在区间 [loc,loc+scale] 上均匀分布，而区间内概率密度函数的取值，满足处处相等，这是它最重要、也是最显著的特征。\n最后我们来实际对均匀分布进行采样，结束我们本篇的内容。\n代码片段：\nfrom scipy.stats import uniform import matplotlib.pyplot as plt import numpy as np import seaborn seaborn.set() x = np.linspace(0, 3.5, 1000) uniform_rv = uniform(1, 2) uniform_rvs = uniform_rv.rvs(100000) plt.plot(x, uniform_rv.pdf(x), 'r-', lw=5, alpha=0.6, label='[1,3]') plt.hist(uniform_rvs, color='b', normed=True, alpha=0.6, bins=50, edgecolor='k') plt.legend(loc='best', frameon=False) plt.show() 运行结果：\n小结 #  至此，经过这两篇内容的介绍，我们学完了离散型和连续型两类单一随机变量的有关内容，并进行了程序实践。在接下来的三篇文章里，我们将重点围绕多元随机变量展开学习和讨论。\n"},{"id":29,"href":"/posts/%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%88%86%E5%B8%83%E4%B8%8E%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81/","title":"离散型随机变量：分布与数字特征","section":"Posts","content":"从事件到随机变量 #  在前面两篇内容中，我们介绍了事件概率的一些基本概念，给大家找了找概率的感觉，对于“试验”、“试验结果”、“事件发生的概率”等等重要概念有了直观的认识，那么我们进一步来讨论一个新的概念。\n我们可以把某一次具体试验中所有可能出现的结果构成一个样本空间，对于样本空间中的每一个可能的试验结果，我们去将他关联到一个特定的数。这种试验结果与数的对应关系就形成了随机变量，将试验结果所对应的数称为随机变量的取值。这里就是接下来要讨论的重要内容。\n请注意这个概念中的一个关键点，随机变量如何取值？他可以直接就是试验的结果取值，比如“抛掷骰子的结果点数为 5”。\n但是，随机变量更多的是这种情况，比如随机变量可以是“连续抛掷硬币 10 次，其中硬币正面出现的次数”，或者是“转了一道弯”的映射值：我们把骰子连续抛掷两次，随机变量对应连续两次试验中的最大值或者点数之和，这就是映射的情况。但是无论如何，对于随机变量，都必须要明确对应具体的取值。\n离散型随机变量及其要素 #  读者们很容易联想到，随机变量作为一种映射后的取值，本质上和函数取值一样，可以有连续型和离散型两种，在这一篇里，我们主要讨论离散型的情况和应用场景，连续型的情况放在下一篇来讲解。\n对于连续和离散的概念，大家脑海里的直观印象往往更加简单，但具体怎么用形式化的概念语言来描述他，反而要更繁琐一些。我们还是严格的对离散型随机变量做一个定义，即：随机变量的取值只能是有限多个或者是可数的无限多个值。\n那么对于任意的我们获取的一组随机变量，最关注的是哪些要素呢？我来列举一下：\n第一：随机变量的取值。 显然这个是我们首先需要关注的，由试验结果派生出的这一组随机变量到底能取到哪些值，这是我们首要关注的问题点。\n第二：试验中每个对应取值的概率。 每个事件的结果肯定不是等概率的，这也恰恰就是我们研究的出发点。\n第三：随机变量的统计特征和度量方法。 弄清楚随机变量每一个具体的取值，我们把握的是他的个体特征，那么如何从整个上来把握这一组随机变量的统计特征呢？这也是非常重要的。\n结合三个问题，来讨论一下离散型随机变量的分布\n离散型随机变量的分布列 #  分布列描述的就是离散型随机变量每一种取值及其对应的概率，随机变量一般用大写字母表示，其具体的取值一般用小写字母来表示。例如，随机变量 X 的分布列，我们一般用 pX，而用 x 来表示随机变量 X 的某个具体取值，因此把上述信息合起来就有：\n随机变量 X 取值为 x 的概率，本质上也是一个事件的概率，这个事件就是 {X=x}，我们将他记作：PX(x)=P({X=x})。\n为了更清楚的解释这个式子，我们还是回到抛硬币这个最简单的情况中来。随机变量 X 表示两次抛掷硬币正面向上的次数，随机变量 X 的分布列如下表所示：\n   取值 0 1 2 其他     P|14|12|14 0       从上面的随机变量分布列中我们可以清晰地看出随机变量 X 的每一种取值以及所对应的取值概率。例如，正面向上的次数为 1 时，对应的事件概率为 12。\n这个分布列虽然非常简单，但是麻雀虽小五脏俱全，下面我们来重点关注里面最重要的两个要点。\n第一，对于随机变量 X 的所有可能取值，其概率之和为 1，表示成表达式就是：∑xPX(x)=1\n第二，对于随机变量 X 的不同取值 x，对应的事件 {X=x} 彼此之间是互不相容的。因此多个事件构成的事件集合 S 的发生概率，可以通过对应事件发生的概率直接相加得到。即：P(X∈S)=∑x∈SpX(x)\n举个例子，比如我们想计算一下连续两次抛掷硬币，出现正面向上的概率为多大，这个事件集合实际上包含了两个事件：事件 1 是 {X=1}，事件 2 是 {X=2}，二者彼此是互不相容的，我们按照上面的式子可以得出其概率：\nP(X\u0026gt;0)=∑2x=1pX(x)=PX(1)+PX(2)=12+14=34\n分布列和概率质量函数 PMF #  一般情况下，我们最好是结合图形来观察一个随机变量的分布，这样一来，他的特性就能够非常直观的展现出来。\n这里，就不得不提一下概率质量函数（PMF），概率质量函数就是将随机变量的每个值映射到其概率上，看上去和分布列就是一回事儿。\n以上，就讲清楚了离散型随机变量的基本概念。下面开始详细介绍几种常见且非常重要的随机变量，并且借助 Python 工具来进行随机变量的生成和概率的展示。\n二项分布及二项随机变量 #  分布列及 PMF #  我们还是举抛硬币的例子：将一个硬币抛掷 n 次，每次抛掷出现正面的概率为 p，每次抛掷彼此之间都是相互独立的，随机变量 X 对应 n 次抛掷得到的是正面的次数。\n这里，随机变量 X 服从二项分布，二项分布中的核心参数就是上面提到的 n 和 p，随机变量的分布列可以通过下面这个熟悉的公式计算得到：\npX(k)=P(X=k)=(nk)pk(1−p)n−k\n下面通过依次指定不同的 (n,p) 参数：(10,0.25),(10,0.5),(10,0.8)，来绘制 PMF 图，来观察一下二项随机变量的分布情况。\n代码片段：\nfrom scipy.stats import binom import matplotlib.pyplot as plt import seaborn seaborn.set() fig, ax = plt.subplots(3, 1) params = [(10, 0.25), (10, 0.5), (10, 0.8)] x = range(0, 11) for i in range(len(params)): binom_rv = binom(n=params[i][0], p=params[i][1]) ax[i].set_title('n={},p={}'.format(params[i][0], params[i][1])) ax[i].plot(x, binom_rv.pmf(x), 'bo', ms=8) ax[i].vlines(x, 0, binom_rv.pmf(x), colors='b', lw=3) ax[i].set_xlim(0, 10) ax[i].set_ylim(0, 0.35) ax[i].set_xticks(x) ax[i].set_yticks([0, 0.1, 0.2, 0.3]) plt.show() 运行结果：\n挺好看的一张图，我们来简要解释一下代码：\n 第 11 行： 生成服从指定参数 n, p 的二项分布随机变量。 第 12 行~第 18 行： 分别对其进行 PMF 图绘制，因为是离散型随机变量，因此不建议画成折线图，这种形态更为合适一些。  在这个例子中，我们直接通过 scipy 中的 stats 模块得到的二项分布的概率质量函数，也就是反映了不同参数条件下，随机变量 X 各取值点所对应的取值概率。\n随机变量的采样 #  我们可以使用 binom 模块中的 rvs 方法进行二项随机变量的采样模拟，我们可以指定所要采样的随机变量个数，这里指定重复采样 10 万次。我们使用三组参数 (n,p)，分别是(10,0.25)，(10,0.5) 和 (10,0.8)。\n通过上述模拟采样试验可以得到每种实验结果所对应的次数，然后我们通过归一化，可以计算出随机变量每一种取值所对应的频数，并将其作为概率的近似进行绘图观察。\n代码片段：\nfrom scipy.stats import binom import matplotlib.pyplot as plt import seaborn seaborn.set() fig, ax = plt.subplots(3, 1) params = [(10, 0.25), (10, 0.5), (10, 0.8)] x = range(0, 11) for i in range(len(params)): binom_rv = binom(n=params[i][0], p=params[i][1]) rvs = binom_rv.rvs(size=100000) ax[i].hist(rvs, bins=11, normed=True) ax[i].set_title('n={},p={}'.format(params[i][0], params[i][1])) ax[i].set_xlim(0, 10) ax[i].set_ylim(0, 0.4) ax[i].set_xticks(x) print('rvs{}:{}'.format(i, rvs)) plt.show() 运行结果：\nrvs0:[0 4 2 ... 3 2 3] rvs1:[6 6 5 ... 5 7 8] rvs2:[7 8 9 ... 9 7 8] 程序打印的结果是三个数组，这就是我们在不同参数下分别做 10 万次采样试验的结果数组。\n随机变量的数字特征 #  服从二项分布的随机变量，他的期望和方差的表示很简单，服从参数为 (n,p) 的二项分布的随机变量 X，他的期望和方差的公式我们直接给出来：\n期望：E[X]=np\n方差：V[X]=np(1−p)\n我们可以结合上面的试验，用几种方法来验证一下上述结论：\n代码片段：\nimport numpy as np from scipy.stats import binom binom_rv = binom(n=10, p=0.25) mean, var, skew, kurt = binom_rv.stats(moments='mvsk') binom_rvs = binom_rv.rvs(size=100000) E_sim = np.mean(binom_rvs) S_sim = np.std(binom_rvs) V_sim = S_sim * S_sim print('mean={},var={}'.format(mean,var)) print('E_sim={},V_sim={}'.format(E_sim,V_sim)) print('E=np={},V=np(1-p)={}'.format(10 * 0.25,10 * 0.25 * 0.75)) 运行结果：\nmean=2.5,var=1.875 E_sim=2.50569,V_sim=1.8735076238999997 E=np=2.5,V=np(1-p)=1.875 我们用三种方法计算了服从参数为 (n=10,p=0.25) 的二项分布随机变量的均值和方差，其中：\n 第 4 行~第 5 行： 是用函数包中的方法计算的分布的各个理论统计值； 第 7 行~第 10 行： 从采样试验中得到的样本数据计算出来的均值和方差； 第 14 行： 通过公式直接计算出来的理论值。  看的出，利用采样样本数据计算出来的值和理论值基本上是相等的。\n几何分布与几何随机变量 #  几何分布的应用场景 #  我们在二项分布的基础上再来介绍几何分布，在连续抛掷硬币的试验中，每次抛掷出现正面的概率为 p，出现反面的概率为 1−p，在这种背景下，几何随机变量 X 就用来表示连续抛掷硬币直到第一次出现正面所需要的抛掷次数。\n或者我们再举一个直白点的例子，学校里有 10 个白富美女生（假定她们互相不认识，保证独立性），你依次去找她们表白，只要有一个成功了，你就结束了单身狗的日子。但是表白成功的概率为 p，当然，成功的概率肯定不大，但是你秉持着死皮赖脸、死缠烂打，不成功誓不罢休的精神，只要女神拒绝你的表白，就换一个女神继续表白，直到某一个女神答应你为止，那么你一共表白过的总的次数，就是几何型的随机变量。\n几何分布的 PMF 图 #  我们还是先绘制几何分布的 PMF 图，方法和二项分布并无二致。\n代码片段：\nfrom scipy.stats import geom import matplotlib.pyplot as plt import seaborn seaborn.set() fig, ax = plt.subplots(2, 1) params = [0.5, 0.25] x = range(1, 11) for i in range(len(params)): geom_rv = geom(p=params[i]) ax[i].set_title('p={}'.format(params[i])) ax[i].plot(x, geom_rv.pmf(x), 'bo', ms=8) ax[i].vlines(x, 0, geom_rv.pmf(x), colors='b', lw=5) ax[i].set_xlim(0, 10) ax[i].set_ylim(0, 0.6) ax[i].set_xticks(x) ax[i].set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5]) plt.show() 运行结果：\n采样试验和数字特征 #  同样的，我们进行 10 万次采样试验，来观察验证一下，同时观察他的统计特征。\n代码片段：\nfrom scipy.stats import geom import matplotlib.pyplot as plt import seaborn seaborn.set() x = range(1, 21) geom_rv = geom(p=0.5) geom_rvs = geom_rv.rvs(size=100000) plt.hist(geom_rvs, bins=20, normed=True) plt.gca().axes.set_xticks(range(1,21)) mean, var, skew, kurt = geom_rv.stats(moments='mvsk') print('mean={},var={}'.format(mean,var)) plt.show() 运行结果：\nmean=2.0,var=2.0 总结一下，几何分布的期望和方差分别为：\nE[X]=1p\nV[X]=1−pp2\n泊松分布及泊松随机变量 #  泊松分布的应用场景 #  我们刚刚讲了，n 次独立的伯努利试验成功的次数是一个服从二项分布的随机变量，其中参数为 n 和 p，期望为 np。我们这里看一种非常特殊的情况就是：n 非常大，p 非常小，但是期望 np 结果适中。\n现实生活中有没有这类情况？有，比如我们考虑任何一天内发生飞机事故的总数，记作随机变量 X，总共飞机飞行的次数 n 非常大，但是单架次飞机出现事故的概率 p 非常小。或者用随机变量 X 表示一本书中字印刷错误的次数，n 表示一本书中的总字数，非常大，而 p 表示每个字印刷出错的概率，非常小。\n这种情况下，n 很大 p 很小，二项分布的分布列可以简化为我们这里谈到的泊松分布的分布列：\npX(k)=e−λλkk!\n其中，\nλ=np，k=0,1,2,\u0026hellip;\n期望和方差满足：\nE[X]=λ\nV[X]=λ\n特别的，当我们的 n→∞，且 p=λ/n→0 时，对应的二项分布列：\npX(k)=P(X=k)=(nk)pk(1−p)n−k 就收敛于上面的泊松分布列了。\n通俗点说把，就是只要当 λ=np，且 n 非常大，p 非常小，泊松分布就是二项分布的一个非常好的近似。计算简便就是他的一个很大的优势。\n泊松分布的 PMF 图 #  同样的，我们也用 Python 代码来画一下他的 PMF 函数图，对应的观察一下指定参数下泊松分布的分布列。\n正如我们所说，泊松分布的参数就是一个 λ，我们分别绘制一个 λ=10 和 λ=2 的泊松分布 PMF 图，并获取他们的均值和方差。\n代码片段：\nfrom scipy.stats import poisson import matplotlib.pyplot as plt import seaborn seaborn.set() fig, ax = plt.subplots(2, 1) x = range(0, 20) params = [10, 2] for i in range(len(params)): poisson_rv = poisson(mu=params[i]) mean, var, skew, kurt = poisson_rv.stats(moments='mvsk') ax[i].plot(x, poisson_rv.pmf(x), 'bo', ms=8) ax[i].vlines(x, 0, poisson_rv.pmf(x), colors='b', lw=5) ax[i].set_title('`$\\\\lambda$`={}'.format(params[i])) ax[i].set_xticks(x) print('lambda={},E[X]={},V[X]={}'.format(params[i], mean, var)) plt.show() 运行结果：\nlambda=10,E[X]=10.0,V[X]=10.0 lambda=2,E[X]=2.0,V[X]=2.0 同样的，我们对 λ=2 的泊松分布进行采样。\n代码片段：\nimport numpy as np from scipy.stats import poisson import matplotlib.pyplot as plt import seaborn seaborn.set() lambda_ = 2 data = poisson.rvs(mu=lambda_, size=100000) plt.figure() plt.hist(data, normed=True) plt.gca().axes.set_xticks(range(0, 11)) print('mean=', np.mean(data)) print('var=', np.square(np.std(data))) plt.show() 运行结果：\nmean= 2.00542 var= 2.0082906236 这也是我们通过 10 万次采样试验得出的统计结果，我们通过这个结果集计算了均值和方差，和模型的理论推导值是一致的。\n离散型随机变量的内容就暂时到这，在下一篇，我们将介绍连续型随机变量的有关内容。\n"},{"id":30,"href":"/posts/git-failed/","title":"fatal: unable to access server certificate verification failed","section":"Posts","content":"git clone时遇到fatal: unable to access server certificate verification failed #  git clone 时遇到这样的问题：\nfatal: unable to access \u0026lsquo;https://*.git\u0026rsquo;: server certificate verification failed. CAfile: none CRLfile: none\n解决办法：\ngit config --global http.sslverify false "},{"id":31,"href":"/docs/project/","title":"Project","section":"Docs","content":"About Project #  "},{"id":32,"href":"/docs/project/cosmono/","title":"Cosmono","section":"Project","content":"About Cosmono #  "},{"id":33,"href":"/docs/project/cosmorg/","title":"Cosmorg","section":"Project","content":"About Cosmorg #  "},{"id":34,"href":"/docs/project/cosmoto/","title":"Cosmoto","section":"Project","content":"About Cosmoto #  "},{"id":35,"href":"/posts/%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%85%B3%E7%B3%BB%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E7%8B%AC%E7%AB%8B%E6%80%A7/","title":"事件的关系：深入理解独立性","section":"Posts","content":"事件的关系：深入理解独立性 #  重新梳理两个事件的独立性 #  在上一篇中，我们引入了条件概率 P(A|B) 这个重要概念，何谓条件概率？条件概率的核心就是刻画了事件 B 的发生给事件 A 是否发生所带来的额外信息。\n在所有的条件概率情况当中，我们注意到一个有趣且重要的特殊情况，那就是事件 B 的发生并没有给事件 A的发生带来什么新的额外信息。换言之，事件 B 的发生与否，并没有影响到事件 A 发生的概率，换句话说就是 P(A|B)=P(A) 所表达的意思。\n此时，我们称事件 A 是独立于事件 B 的，并由条件概率公式 P(A|B)=P(A∩B)P(B) 可以进一步推导出等价的表达式：P(A∩B)=P(A)P(B)。\n到这里，就是我们所回顾的上一篇中谈论到的两个事件相互独立的核心概念。\n不相容与独立性 #  我们首先看看下面这幅图中所描述的情况：\n在图中，表示事件 A 和事件 B 的两个圆圈互不相交，即意味着两个事件不相容，你会不会直观的感觉到，事件 A 和事件 B 二者看上去没啥关系，二者就是相互独立的？\n这个说法看似很有道理，然而事实上却恰巧相反。若事件 A 和事件 B 互不相容，并且像图中所描述的，能够保证两个事件发生的概率：P(A)\u0026gt;0 且 P(B)\u0026gt;0 成立，则他们永远不会相互独立。\n这是为什么呢？我们直接抠定义就好了。这是因为：首先有 A∩B=ϕ，那么显然有联合概率 P(A∩B)=0，而由于 P(A) 和 P(B) 均大于 0，则有 P(A)P(B)≠0 。因此，从 P(A∩B)≠P(A)P(B) 的结果来看，并不满足事件 A 和事件 B 相互独立的基本条件。\n其实，这个结果从常理上来说我们也很好理解，由于事件 A 和事件 B 不相容，从图中可以看出，如果事件 B发生，则意味着事件 A 一定不会发生，那么这就实际上说明了：事件 B 的发生就给事件 A 的发生引入了额外的信息。那么，二者显然就不是互相独立的了。\n条件独立 #  条件独立的直观感受 #  我们在前面讨论了条件概率的内容，自然的直觉告诉我们，我们也应该在条件概率的框架之下来讨论事件之间的独立性，即探讨条件独立的概念。\n条件独立的概念其实和独立的概念在本质上并没有太大的区别，无非是在进行事件 A 和事件 B 讨论的基础上，引入了另外一个前提条件：事件 C。即在给定事件 C 发生的前提条件之下，若事件 A 和事件 B 满足等式：P(A∩B|C)=P(A|C)P(B|C) 成立，我们就说事件 A 和事件 B 在给定事件 C 的前提之下条件独立。这是不是和独立性的定义基本上差不多呢？\n条件独立的表达式 #  同样的，我们先对 P(A∩B|C) 这个式子进行简单的变形处理：\nP(A∩B|C)=P(A∩B∩C)P(C)=P(C)P(B|C)P(A|B∩C)P(C)=P(B|C)P(A|B∩C)\n其实，在短短这几步的推导里面，涉及到了不少的知识内涵，我们下面来一一解析。\n首先，我们依照条件概率的定义，可以得到第一步推导结果：\nP(A∩B|C)=P(A∩B∩C)P(C)\n而第二个推导的等式，则是在条件概率应用领域当中使用非常广泛的链式法则：\nP(A∩B∩C)=P(B∩C)P(A|B∩C)=P(C)P(B|C)P(A|B∩C)\n最后，我们结合 P(A∩B|C)=P(B|C)P(A|B∩C) 这个等式和条件独立的定义式 P(A∩B|C)=P(A|C)P(B|C)，会发现他们拥有相同的等式左侧。因此将两个等式的右侧划上等号，就可以得到：P(B|C)P(A|B∩C)=P(A|C)P(B|C)\n最终我们就获得了这么一个等式：P(A|B∩C)=P(A|C)\n这个等式是条件独立的另一个等价定义，也是非常直观的一个等式。这个等式说明了在给定事件 C 发生的前提条件下，进一步假定此时如果事件 B 也发生，并不会影响事件 A 的发生概率（当然这里是指在事件 C 发生前提下，事件 A 发生的条件概率）。\n简单点说，就是在事件 C 发生的总的前提条件下，事件 B 是否发生，不影响事件 A 发生的概率。其实这就又回到了条件概率定义的源头上去了。\n独立与条件独立 #  这里，我们停下来仔细思考一个重要的概念问题，就是事件 A 和事件 B 相互独立和在事件 C 发生的基础上条件独立是不是等价的呢？直观上看觉得似乎应该能，但是事实上呢？我们看看下面这个例子：\n我们举一个非常简单的例子。\n假设依次抛掷两枚均匀的硬币，事件 A 表示第一枚硬币正面向上，事件 B 表示第二枚硬币正面向上。\n首先，事件 A 和事件 B 肯定是相互独立的。那我们此时引入一个条件事件 C，事件 C 表示两次试验的结果不同。那么显然，概率 P(A∩B|C)=0 因为在两次试验结果不同的前提条件下，压根不可能发生两次都是正面的情况。\n而另一方面呢？显然两个单独的条件概率 P(A|C)≠0，P(B|C)≠0，因此 P(A∩B|C)≠P(A|C)P(B|C)，也就是说事件 A 和事件 B 不满足事件 C 发生下的条件独立的要求。\n这个例子非常明确的说明了，独立和条件独立并不等价。\n一组事件的独立性 #  最后，我们将两个事件相互独立的概念进一步推广到多个事件之间的相互独立性。为了方便我们直观理解，这里我们先将多个事件约定为 3 个，讨论清楚了 3 个事件独立的情况之后，其他的情况自然而然就迎刃而解了。\n关于事件 A1 , A2 , A3，这 3 个事件满足相互独立的条件归结为以下 4 条：\nP(A1∩A2)=P(A1)P(A2)\nP(A1∩A3)=P(A1)P(A3)\nP(A2∩A3)=P(A2)P(A3)\nP(A1∩A2∩A3)=P(A1)P(A2)P(A3)\n首先我们看到，前面的三个等式说明了任意两个事件之间是相互独立的，这种性质称之为两两独立。但是这并没有结束，第四个条件也是必要的，他并不是前面三个等式的推论，他无法仅仅通过前面三个条件成立就能得到。反过来，第四个条件成立也不能推导出前面三个条件的成立。\n简单点说吧，就是上面这四个条件必须全部检验、全部满足，才能够说这三个事件之间满足独立性。\n还是用上面那个抛硬币的那个例子，事件 A 表示第一枚硬币正面向上，事件 B 表示第二枚硬币正面向上，事件 C 表示两次试验的结果不同。\n首先事件 A 和事件 C 显然满足：P(C)=P(C|A)=12，即事件 A 和事件 C 独立，同理可知事件 B 和事件 C 独立，同时我们知道事件 A 和事件 B 也满足独立性。\n但是到目前为止，即便前三个条件都满足了，此时第四个等式仍然不能满足：即 P(A∩B∩C)=0，P(A)P(B)P(C)=18，这两个等式并不相等。\n最后由特殊到一般，我们来概况一下任意个数的一组事件之间相互独立应该满足的条件：\nP(⋂i∈SAi)=∏i∈SP(Ai) 对 {1,2,\u0026hellip;,n} 的任意子集 S 都成立，则称 A1,\u0026hellip;,An 为相互独立的事件。\n脱离开上面形式化的公式，实际上，我们可以更加直观的来理解一组事件的独立性。通过对比，其实不难发现他的背景与两个事件的独立性是一样的。一组事件满足独立性意味着下面一个事实：我们把一组事件任意的分成两个小组，一个小组中的任意个数事件的出现与不出现，都不会给另一个小组中事件的发生与否带来任何额外的信息。\n独立重复试验 #  在介绍完了事件独立性的基础上，我们再来简单的提一下大家耳熟能详的独立重复试验。\n如果某一个试验由一系列独立并且相同的小试验组成，我们称这种试验为独立重复试验。当每个小试验只有两种可能结果的时候，就是我们最为常见的伯努利试验。\n这里最简单的例子就是抛硬币。例如，连续 n 次独立地抛掷硬币，每次抛掷的结果为正面的概率记作 p。这里的独立指得就是每次试验的事件 A1,A2,\u0026hellip;,An 都是独立的，其中 Ai 表示第 i 次抛掷的结果为正面。独立性就意味着不管前面的抛掷结果如何，每次抛掷得到正面的概率都是 p。\n因此最终我们可以知道，在 n 次试验中，有 k 次试验结果为正面的概率为：\np(k)=(nk)pk(1−p)n−k\n当然这个例子本身非常简单，大家也都非常熟悉，这里只是为了再强调一下独立的含义，演示一个独立重复试验的过程。独立重复试验的概念和场景将在我们后面的课程内容中反复多次出现。\n分享交流 #  我们为本专栏付费读者创建了微信交流群，以方便更有针对性地讨论专栏相关的问题。入群方式请添加 GitChat 小助手伽利略的微信号：GitChatty6（或扫描以下二维码），然后给小助手发「279」消息，即可拉你进群~\n"}]